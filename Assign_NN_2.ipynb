{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6a98426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b0ca763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\Abel\\Downloads\\gas_turbines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d20599c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0  6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1  6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2  6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3  7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4  7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "\n",
       "       CO     NOX  \n",
       "0  3.1547  82.722  \n",
       "1  3.2363  82.776  \n",
       "2  3.2012  82.468  \n",
       "3  3.1923  82.670  \n",
       "4  3.2484  82.311  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0965052f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.00000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.764381</td>\n",
       "      <td>1013.19924</td>\n",
       "      <td>79.124174</td>\n",
       "      <td>4.200294</td>\n",
       "      <td>25.419061</td>\n",
       "      <td>1083.798770</td>\n",
       "      <td>545.396183</td>\n",
       "      <td>134.188464</td>\n",
       "      <td>12.102353</td>\n",
       "      <td>1.972499</td>\n",
       "      <td>68.190934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.574323</td>\n",
       "      <td>6.41076</td>\n",
       "      <td>13.793439</td>\n",
       "      <td>0.760197</td>\n",
       "      <td>4.173916</td>\n",
       "      <td>16.527806</td>\n",
       "      <td>7.866803</td>\n",
       "      <td>15.829717</td>\n",
       "      <td>1.103196</td>\n",
       "      <td>2.222206</td>\n",
       "      <td>10.470586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.522300</td>\n",
       "      <td>985.85000</td>\n",
       "      <td>30.344000</td>\n",
       "      <td>2.087400</td>\n",
       "      <td>17.878000</td>\n",
       "      <td>1000.800000</td>\n",
       "      <td>512.450000</td>\n",
       "      <td>100.170000</td>\n",
       "      <td>9.904400</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>27.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.408000</td>\n",
       "      <td>1008.90000</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>3.723900</td>\n",
       "      <td>23.294000</td>\n",
       "      <td>1079.600000</td>\n",
       "      <td>542.170000</td>\n",
       "      <td>127.985000</td>\n",
       "      <td>11.622000</td>\n",
       "      <td>0.858055</td>\n",
       "      <td>61.303500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.186000</td>\n",
       "      <td>1012.80000</td>\n",
       "      <td>82.266000</td>\n",
       "      <td>4.186200</td>\n",
       "      <td>25.082000</td>\n",
       "      <td>1088.700000</td>\n",
       "      <td>549.890000</td>\n",
       "      <td>133.780000</td>\n",
       "      <td>12.025000</td>\n",
       "      <td>1.390200</td>\n",
       "      <td>66.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.862500</td>\n",
       "      <td>1016.90000</td>\n",
       "      <td>90.043500</td>\n",
       "      <td>4.550900</td>\n",
       "      <td>27.184000</td>\n",
       "      <td>1096.000000</td>\n",
       "      <td>550.060000</td>\n",
       "      <td>140.895000</td>\n",
       "      <td>12.578000</td>\n",
       "      <td>2.160400</td>\n",
       "      <td>73.935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34.929000</td>\n",
       "      <td>1034.20000</td>\n",
       "      <td>100.200000</td>\n",
       "      <td>7.610600</td>\n",
       "      <td>37.402000</td>\n",
       "      <td>1100.800000</td>\n",
       "      <td>550.610000</td>\n",
       "      <td>174.610000</td>\n",
       "      <td>15.081000</td>\n",
       "      <td>44.103000</td>\n",
       "      <td>119.890000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AT           AP            AH          AFDP          GTEP  \\\n",
       "count  15039.000000  15039.00000  15039.000000  15039.000000  15039.000000   \n",
       "mean      17.764381   1013.19924     79.124174      4.200294     25.419061   \n",
       "std        7.574323      6.41076     13.793439      0.760197      4.173916   \n",
       "min        0.522300    985.85000     30.344000      2.087400     17.878000   \n",
       "25%       11.408000   1008.90000     69.750000      3.723900     23.294000   \n",
       "50%       18.186000   1012.80000     82.266000      4.186200     25.082000   \n",
       "75%       23.862500   1016.90000     90.043500      4.550900     27.184000   \n",
       "max       34.929000   1034.20000    100.200000      7.610600     37.402000   \n",
       "\n",
       "                TIT           TAT           TEY           CDP            CO  \\\n",
       "count  15039.000000  15039.000000  15039.000000  15039.000000  15039.000000   \n",
       "mean    1083.798770    545.396183    134.188464     12.102353      1.972499   \n",
       "std       16.527806      7.866803     15.829717      1.103196      2.222206   \n",
       "min     1000.800000    512.450000    100.170000      9.904400      0.000388   \n",
       "25%     1079.600000    542.170000    127.985000     11.622000      0.858055   \n",
       "50%     1088.700000    549.890000    133.780000     12.025000      1.390200   \n",
       "75%     1096.000000    550.060000    140.895000     12.578000      2.160400   \n",
       "max     1100.800000    550.610000    174.610000     15.081000     44.103000   \n",
       "\n",
       "                NOX  \n",
       "count  15039.000000  \n",
       "mean      68.190934  \n",
       "std       10.470586  \n",
       "min       27.765000  \n",
       "25%       61.303500  \n",
       "50%       66.601000  \n",
       "75%       73.935500  \n",
       "max      119.890000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6629edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40c2f8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15039, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4391d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='TEY', ylabel='Count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x='TEY',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc4b50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,0:3]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std=StandardScaler()\n",
    "x_std=std.fit_transform(x)\n",
    "X=x_std\n",
    "Y=df.iloc[:,-4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d94df84",
   "metadata": {},
   "source": [
    "## Grid Search for best epochs and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59668c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary packages\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a50c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():    \n",
    "    model=Sequential()\n",
    "    model.add(Dense(10,input_dim=3,kernel_initializer='uniform',activation='relu'))\n",
    "    model.add(Dense(8,activation='relu'))\n",
    "    model.add(Dense(12,activation='relu'))\n",
    "    model.add(Dense(1,activation='linear'))\n",
    "\n",
    "    model.compile(loss ='mean_squared_error',optimizer=Adam(learning_rate=0.5),metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3ac3023",
   "metadata": {},
   "outputs": [],
   "source": [
    "kr=KerasRegressor(build_fn=create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d2aaf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=GridSearchCV(estimator=kr,param_grid={'epochs':[10,50,60,100],'batch_size':[1000,3000,5000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daf44b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 0s 831us/step - loss: 14980.0608 - mse: 14980.0608\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 4019.0429 - mse: 4019.0429\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 961.8724 - mse: 961.8724\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 748us/step - loss: 363.6160 - mse: 363.6160\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 748us/step - loss: 242.4973 - mse: 242.4973\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 748us/step - loss: 213.5000 - mse: 213.5000\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.2678 - mse: 209.2678\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 200.6908 - mse: 200.6908\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 202.0493 - mse: 202.0493\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 748us/step - loss: 198.9046 - mse: 198.9046\n",
      "4/4 [==============================] - 0s 998us/step - loss: 306.6729 - mse: 306.6729\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 0s 748us/step - loss: 8153.8511 - mse: 8153.8511\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 582us/step - loss: 762.3846 - mse: 762.3846\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 327.2431 - mse: 327.2431\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 274.9987 - mse: 274.9987\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 255.9008 - mse: 255.9008\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 252.9175 - mse: 252.9175\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 748us/step - loss: 267.3241 - mse: 267.3241\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 748us/step - loss: 294.1234 - mse: 294.1234\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 748us/step - loss: 379.6359 - mse: 379.6359\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 303.1856 - mse: 303.1856\n",
      "4/4 [==============================] - 0s 665us/step - loss: 111.3344 - mse: 111.3344\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 0s 747us/step - loss: 41032.8816 - mse: 41032.8816\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 17185.8597 - mse: 17185.8597\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 16001.7273 - mse: 16001.7273\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 14609.2039 - mse: 14609.2039\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 13301.8010 - mse: 13301.8010\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 748us/step - loss: 12018.0760 - mse: 12018.0760\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 748us/step - loss: 10872.1817 - mse: 10872.1817\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 9765.5701 - mse: 9765.5701\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 748us/step - loss: 8758.3719 - mse: 8758.3719\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 748us/step - loss: 7851.2359 - mse: 7851.2359\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 8188.5532 - mse: 8188.5532\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 0s 748us/step - loss: 11357.0965 - mse: 11357.0965\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 1609.3972 - mse: 1609.3972\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 419.9916 - mse: 419.9916\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 282.3847 - mse: 282.3847\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 246.5405 - mse: 246.5405\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 221.2415 - mse: 221.2415\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 219.2824 - mse: 219.2824\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 831us/step - loss: 219.9277 - mse: 219.9277\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 748us/step - loss: 236.7952 - mse: 236.7952\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 225.5883 - mse: 225.5883\n",
      "4/4 [==============================] - 0s 998us/step - loss: 278.4009 - mse: 278.4009\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 0s 748us/step - loss: 17145.8223 - mse: 17145.8223\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 10202.9006 - mse: 10202.9006\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 582us/step - loss: 2025.0737 - mse: 2025.0737\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 938.9329 - mse: 938.9329\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 748us/step - loss: 384.8390 - mse: 384.8390\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 253.3700 - mse: 253.3700\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 410.7189 - mse: 410.7189\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 257.6229 - mse: 257.6229\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 665us/step - loss: 235.5245 - mse: 235.5245\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 748us/step - loss: 234.1288 - mse: 234.1288\n",
      "4/4 [==============================] - 0s 998us/step - loss: 289.8936 - mse: 289.8936\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 20259.4869 - mse: 20259.4869\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 16679.1682 - mse: 16679.1687\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 14800.3654 - mse: 14800.3654\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 7396.2016 - mse: 7396.2016\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 2032.6762 - mse: 2032.6762\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 770.0017 - mse: 770.0017\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 384.3809 - mse: 384.3809\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 319.6856 - mse: 319.6856\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 260.2493 - mse: 260.2493\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 230.3788 - mse: 230.3788\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 229.7940 - mse: 229.7940\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 228.5909 - mse: 228.5909\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 232.9526 - mse: 232.9526\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.7810 - mse: 213.7810\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 214.1429 - mse: 214.1429\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 199.7626 - mse: 199.7626\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 197.2644 - mse: 197.2644\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 197.4652 - mse: 197.4652\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 205.8681 - mse: 205.8681\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 582us/step - loss: 200.1305 - mse: 200.1305\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 193.5009 - mse: 193.5009\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 198.0762 - mse: 198.0762\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 242.7375 - mse: 242.7375\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 582us/step - loss: 199.7770 - mse: 199.7770\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 199.5207 - mse: 199.5207\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 200.1064 - mse: 200.1064\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 207.1150 - mse: 207.1150\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 204.0445 - mse: 204.0445\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 221.8430 - mse: 221.8430\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.1888 - mse: 218.1888\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 202.9447 - mse: 202.9447\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 195.1520 - mse: 195.1520\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 196.0003 - mse: 196.0003\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 195.6883 - mse: 195.6883\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 204.0492 - mse: 204.0492\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 192.2903 - mse: 192.2903\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 195.6607 - mse: 195.6607\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 226.8627 - mse: 226.8627\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 582us/step - loss: 208.5540 - mse: 208.5540\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 206.0988 - mse: 206.0988\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 212.3547 - mse: 212.3547\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 197.7258 - mse: 197.7258\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 189.8193 - mse: 189.8193\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 582us/step - loss: 209.1657 - mse: 209.1657\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 194.4208 - mse: 194.4208\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 193.5039 - mse: 193.5039\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 196.5574 - mse: 196.5574\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 205.6230 - mse: 205.6230\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.2701 - mse: 218.2701\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 582us/step - loss: 207.6721 - mse: 207.6721\n",
      "4/4 [==============================] - 0s 974us/step - loss: 313.9861 - mse: 313.9861\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 11125.6524 - mse: 11125.6524\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 2377.4129 - mse: 2377.4129\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 459.4221 - mse: 459.4221\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 376.6264 - mse: 376.6264\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 275.4370 - mse: 275.4370\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 253.8857 - mse: 253.8857\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 251.2241 - mse: 251.2241\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 318.6675 - mse: 318.6675\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 264.7759 - mse: 264.7759\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 254.7649 - mse: 254.7649\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 265.0720 - mse: 265.0720\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 582us/step - loss: 250.4092 - mse: 250.4092\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 267.0875 - mse: 267.0875\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 831us/step - loss: 262.6032 - mse: 262.6032\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 624us/step - loss: 321.0388 - mse: 321.0388\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 299.4370 - mse: 299.4370\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 258.6019 - mse: 258.6019\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 250.9438 - mse: 250.9438\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 255.4692 - mse: 255.4692\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 257.1816 - mse: 257.1816\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.5013 - mse: 249.5013\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 247.1960 - mse: 247.1960\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 247.8138 - mse: 247.8138\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 250.0144 - mse: 250.0144\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 283.2070 - mse: 283.2070\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 261.0674 - mse: 261.0674\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 278.9793 - mse: 278.9793\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 259.3649 - mse: 259.3649\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 247.4734 - mse: 247.4734\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 271.0901 - mse: 271.0901\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 251.4643 - mse: 251.4643\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 284.3163 - mse: 284.3163\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.4437 - mse: 249.4437\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 247.2986 - mse: 247.2986\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 259.4928 - mse: 259.4928\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 270.7866 - mse: 270.7866\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 252.4531 - mse: 252.4531\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 252.6975 - mse: 252.6975\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 247.5631 - mse: 247.5631\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 254.2444 - mse: 254.2444\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 348.8264 - mse: 348.8264\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 306.2830 - mse: 306.2830\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 279.6244 - mse: 279.6244\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 662us/step - loss: 270.0202 - mse: 270.0202\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.5141 - mse: 249.5141\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 250.0452 - mse: 250.0452\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 264.9852 - mse: 264.9852\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 292.1105 - mse: 292.1105\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 335.6197 - mse: 335.6197\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 253.7092 - mse: 253.7092\n",
      "4/4 [==============================] - 0s 665us/step - loss: 155.4418 - mse: 155.4418\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 15931.9616 - mse: 15931.9617\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 13440.0232 - mse: 13440.0232\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 3388.8632 - mse: 3388.8632\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 1156.9755 - mse: 1156.9755\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 569.3562 - mse: 569.3562\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 348.2895 - mse: 348.2895\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 262.8176 - mse: 262.8176\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 241.2991 - mse: 241.2991\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 222.3321 - mse: 222.3321\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.6656 - mse: 211.6656\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 214.4637 - mse: 214.4637\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.1934 - mse: 211.1934\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 221.0664 - mse: 221.0664\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.7053 - mse: 211.7053\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 582us/step - loss: 208.6650 - mse: 208.6650\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.3317 - mse: 211.3317\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 582us/step - loss: 219.0326 - mse: 219.0326\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 582us/step - loss: 212.3353 - mse: 212.3353\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.4394 - mse: 211.4394\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 582us/step - loss: 209.2835 - mse: 209.2835\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 207.0139 - mse: 207.0139\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 205.2152 - mse: 205.2152\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 214.8091 - mse: 214.8091\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 201.3731 - mse: 201.3731\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 207.2030 - mse: 207.2030\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 223.4911 - mse: 223.4911\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 223.3249 - mse: 223.3249\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 217.4467 - mse: 217.4467\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.6267 - mse: 213.6267\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.9070 - mse: 209.9070\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.3340 - mse: 209.3340\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.5914 - mse: 209.5914\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 582us/step - loss: 213.0891 - mse: 213.0891\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.0055 - mse: 209.0055\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 217.1967 - mse: 217.1967\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 582us/step - loss: 213.7645 - mse: 213.7645\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 204.5737 - mse: 204.5737\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 205.6020 - mse: 205.6020\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 210.8080 - mse: 210.8080\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 215.8967 - mse: 215.8967\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.5515 - mse: 209.5515\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.0051 - mse: 211.0051\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 207.2169 - mse: 207.2169\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 204.1586 - mse: 204.1586\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 210.1805 - mse: 210.1805\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 210.0663 - mse: 210.0663\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 206.9919 - mse: 206.9919\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 216.3008 - mse: 216.3008\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 219.6839 - mse: 219.6839\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 225.4570 - mse: 225.4570\n",
      "4/4 [==============================] - 0s 998us/step - loss: 348.1918 - mse: 348.1918\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 10858.6568 - mse: 10858.6568\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 1323.8553 - mse: 1323.8553\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 394.5397 - mse: 394.5397\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 275.7841 - mse: 275.7841\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 234.4347 - mse: 234.4347\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 232.3650 - mse: 232.3650\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 227.8727 - mse: 227.8727\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 234.7904 - mse: 234.7904\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 226.5907 - mse: 226.5907\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 227.7680 - mse: 227.7680\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 351.6693 - mse: 351.6693\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 262.6960 - mse: 262.6960\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 233.6302 - mse: 233.6302\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 260.4415 - mse: 260.4415\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 222.7873 - mse: 222.7873\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 225.3363 - mse: 225.3363\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 208.4701 - mse: 208.4701\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 421.6243 - mse: 421.6243\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 582us/step - loss: 311.6261 - mse: 311.6261\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 234.1820 - mse: 234.1820\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 219.0348 - mse: 219.0348\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.0292 - mse: 211.0292\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.2277 - mse: 213.2277\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 221.5583 - mse: 221.5583\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 247.4798 - mse: 247.4798\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 245.2445 - mse: 245.2445\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.5983 - mse: 249.5983\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 272.3147 - mse: 272.3147\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 230.2265 - mse: 230.2265\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 220.5491 - mse: 220.5491\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 230.6457 - mse: 230.6457\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 276.4110 - mse: 276.4110\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.5877 - mse: 213.5877\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.9363 - mse: 218.9363\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.9503 - mse: 213.9503\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 216.7044 - mse: 216.7044\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.9635 - mse: 218.9635\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.8307 - mse: 213.8307\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 217.8191 - mse: 217.8191\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 297.4527 - mse: 297.4527\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 215.0915 - mse: 215.0915\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 640us/step - loss: 223.0530 - mse: 223.0530\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 242.9083 - mse: 242.9083\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 212.8995 - mse: 212.8995\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 223.8241 - mse: 223.8241\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 215.3749 - mse: 215.3749\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 338.5902 - mse: 338.5902\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 283.9293 - mse: 283.9293\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 226.4017 - mse: 226.4017\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 582us/step - loss: 235.0596 - mse: 235.0596\n",
      "4/4 [==============================] - 0s 663us/step - loss: 736.9175 - mse: 736.9175\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 19517.5437 - mse: 19517.5437\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 17323.7381 - mse: 17323.7381\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 15350.9312 - mse: 15350.9312\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 12668.7618 - mse: 12668.7618\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 5447.5437 - mse: 5447.5437\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 652.4580 - mse: 652.4580\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 349.7384 - mse: 349.7384\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 334.7782 - mse: 334.7782\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 265.8755 - mse: 265.8755\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 246.4495 - mse: 246.4495\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 246.9263 - mse: 246.9263\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 244.3849 - mse: 244.3849\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 248.8590 - mse: 248.8590\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 246.5925 - mse: 246.5925\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 250.0847 - mse: 250.0847\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 242.1398 - mse: 242.1398\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 246.7266 - mse: 246.7266\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 251.9914 - mse: 251.9914\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 250.5966 - mse: 250.5966\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 250.8332 - mse: 250.8332\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 251.2591 - mse: 251.2591\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.0573 - mse: 249.0573\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 252.3665 - mse: 252.3665\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 247.5009 - mse: 247.5009\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 253.7756 - mse: 253.7756\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 914us/step - loss: 246.4402 - mse: 246.4402\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 250.9637 - mse: 250.9636\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 248.8106 - mse: 248.8106\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.7731 - mse: 249.7731\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 247.8377 - mse: 247.8377\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 252.6130 - mse: 252.6130\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 250.4334 - mse: 250.4334\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 247.0964 - mse: 247.0964\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 250.6432 - mse: 250.6432\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 250.5927 - mse: 250.5927\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 252.5522 - mse: 252.5522\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 248.9629 - mse: 248.9629\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.8273 - mse: 249.8272\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 748us/step - loss: 250.3768 - mse: 250.3768\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 250.3482 - mse: 250.3482\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.2865 - mse: 249.2865\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 251.0647 - mse: 251.0647\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 243.8316 - mse: 243.8316\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 255.4091 - mse: 255.4091\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.3133 - mse: 249.3133\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 246.4554 - mse: 246.4554\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.9483 - mse: 249.9483\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 248.9628 - mse: 248.9628\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 250.3602 - mse: 250.3602\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 665us/step - loss: 251.8130 - mse: 251.8130\n",
      "4/4 [==============================] - 0s 666us/step - loss: 260.2427 - mse: 260.2427\n",
      "Epoch 1/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 13969.3026 - mse: 13969.3026\n",
      "Epoch 2/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 2308.4436 - mse: 2308.4436\n",
      "Epoch 3/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 657.9754 - mse: 657.9754\n",
      "Epoch 4/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 297.1764 - mse: 297.1764\n",
      "Epoch 5/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 236.2383 - mse: 236.2383\n",
      "Epoch 6/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 216.5471 - mse: 216.5471\n",
      "Epoch 7/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 216.4974 - mse: 216.4974\n",
      "Epoch 8/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 204.1070 - mse: 204.1070\n",
      "Epoch 9/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 208.4076 - mse: 208.4076\n",
      "Epoch 10/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 220.4656 - mse: 220.4656\n",
      "Epoch 11/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 222.8731 - mse: 222.8731\n",
      "Epoch 12/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 215.5440 - mse: 215.5440\n",
      "Epoch 13/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 204.3169 - mse: 204.3169\n",
      "Epoch 14/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 221.5535 - mse: 221.5535\n",
      "Epoch 15/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 222.5216 - mse: 222.5216\n",
      "Epoch 16/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 207.0094 - mse: 207.0094\n",
      "Epoch 17/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 289.1503 - mse: 289.1503\n",
      "Epoch 18/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 205.2566 - mse: 205.2566\n",
      "Epoch 19/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 218.3399 - mse: 218.3399\n",
      "Epoch 20/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 198.7069 - mse: 198.7069\n",
      "Epoch 21/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 203.3149 - mse: 203.3149\n",
      "Epoch 22/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 202.6654 - mse: 202.6654\n",
      "Epoch 23/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 231.9246 - mse: 231.9246\n",
      "Epoch 24/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 228.4571 - mse: 228.4571\n",
      "Epoch 25/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 237.2269 - mse: 237.2269\n",
      "Epoch 26/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 221.5453 - mse: 221.5453\n",
      "Epoch 27/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 253.2705 - mse: 253.2705\n",
      "Epoch 28/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 208.8350 - mse: 208.8350\n",
      "Epoch 29/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 204.1326 - mse: 204.1326\n",
      "Epoch 30/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 195.7618 - mse: 195.7618\n",
      "Epoch 31/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 197.1364 - mse: 197.1364\n",
      "Epoch 32/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 251.3452 - mse: 251.3452\n",
      "Epoch 33/60\n",
      "13/13 [==============================] - 0s 582us/step - loss: 210.2545 - mse: 210.2545\n",
      "Epoch 34/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 195.2939 - mse: 195.2939\n",
      "Epoch 35/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 195.9857 - mse: 195.9857\n",
      "Epoch 36/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 227.5674 - mse: 227.5674\n",
      "Epoch 37/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 190.9514 - mse: 190.9514\n",
      "Epoch 38/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 274.1258 - mse: 274.1258\n",
      "Epoch 39/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 232.2577 - mse: 232.2577\n",
      "Epoch 40/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 198.0923 - mse: 198.0923\n",
      "Epoch 41/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 259.7900 - mse: 259.7900\n",
      "Epoch 42/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 222.6626 - mse: 222.6626\n",
      "Epoch 43/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.3151 - mse: 218.3151\n",
      "Epoch 44/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 196.8365 - mse: 196.8365\n",
      "Epoch 45/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 201.0973 - mse: 201.0973\n",
      "Epoch 46/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 239.7388 - mse: 239.7388\n",
      "Epoch 47/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 208.2992 - mse: 208.2992\n",
      "Epoch 48/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 210.3487 - mse: 210.3487\n",
      "Epoch 49/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 217.6773 - mse: 217.6773\n",
      "Epoch 50/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 222.0574 - mse: 222.0574\n",
      "Epoch 51/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 223.1219 - mse: 223.1219\n",
      "Epoch 52/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 220.9859 - mse: 220.9859\n",
      "Epoch 53/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.9519 - mse: 211.9519\n",
      "Epoch 54/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.6929 - mse: 218.6929\n",
      "Epoch 55/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 223.4743 - mse: 223.4743\n",
      "Epoch 56/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 207.8026 - mse: 207.8026\n",
      "Epoch 57/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 217.9781 - mse: 217.9781\n",
      "Epoch 58/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 217.9479 - mse: 217.9479\n",
      "Epoch 59/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 193.6324 - mse: 193.6324\n",
      "Epoch 60/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 200.7116 - mse: 200.7116\n",
      "4/4 [==============================] - 0s 665us/step - loss: 322.7957 - mse: 322.7957\n",
      "Epoch 1/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 27329.8952 - mse: 27329.8952\n",
      "Epoch 2/60\n",
      "13/13 [==============================] - 0s 582us/step - loss: 6739.6121 - mse: 6739.6121\n",
      "Epoch 3/60\n",
      "13/13 [==============================] - 0s 582us/step - loss: 1059.9801 - mse: 1059.9801\n",
      "Epoch 4/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 356.6795 - mse: 356.6795\n",
      "Epoch 5/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 327.9655 - mse: 327.9655\n",
      "Epoch 6/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 295.5308 - mse: 295.5308\n",
      "Epoch 7/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 283.0877 - mse: 283.0877\n",
      "Epoch 8/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 284.6493 - mse: 284.6493\n",
      "Epoch 9/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 280.4534 - mse: 280.4534\n",
      "Epoch 10/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 285.1312 - mse: 285.1312\n",
      "Epoch 11/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 279.8984 - mse: 279.8984\n",
      "Epoch 12/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 279.6942 - mse: 279.6942\n",
      "Epoch 13/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 279.9406 - mse: 279.9406\n",
      "Epoch 14/60\n",
      "13/13 [==============================] - 0s 582us/step - loss: 283.3628 - mse: 283.3628\n",
      "Epoch 15/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 286.6386 - mse: 286.6386\n",
      "Epoch 16/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 283.4709 - mse: 283.4709\n",
      "Epoch 17/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 284.1085 - mse: 284.1085\n",
      "Epoch 18/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 282.3925 - mse: 282.3925\n",
      "Epoch 19/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 279.9441 - mse: 279.9441\n",
      "Epoch 20/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 285.2320 - mse: 285.2320\n",
      "Epoch 21/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 285.6700 - mse: 285.6700\n",
      "Epoch 22/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 280.5806 - mse: 280.5806\n",
      "Epoch 23/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 280.7214 - mse: 280.7214\n",
      "Epoch 24/60\n",
      "13/13 [==============================] - 0s 582us/step - loss: 280.5787 - mse: 280.5787\n",
      "Epoch 25/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 279.8767 - mse: 279.8767\n",
      "Epoch 26/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 283.9018 - mse: 283.9018\n",
      "Epoch 27/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 279.0444 - mse: 279.0444\n",
      "Epoch 28/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 282.1436 - mse: 282.1436\n",
      "Epoch 29/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 283.1230 - mse: 283.1230\n",
      "Epoch 30/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 280.1919 - mse: 280.1919\n",
      "Epoch 31/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 280.7441 - mse: 280.7441\n",
      "Epoch 32/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 280.8057 - mse: 280.8057\n",
      "Epoch 33/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 277.0507 - mse: 277.0507\n",
      "Epoch 34/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 276.9727 - mse: 276.9727\n",
      "Epoch 35/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 284.0712 - mse: 284.0712\n",
      "Epoch 36/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 277.4524 - mse: 277.4524\n",
      "Epoch 37/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 280.3075 - mse: 280.3075\n",
      "Epoch 38/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 281.3337 - mse: 281.3337\n",
      "Epoch 39/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 287.2698 - mse: 287.2698\n",
      "Epoch 40/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 280.0819 - mse: 280.0819\n",
      "Epoch 41/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 274.4264 - mse: 274.4264\n",
      "Epoch 42/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 278.0161 - mse: 278.0161\n",
      "Epoch 43/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 283.6829 - mse: 283.6829\n",
      "Epoch 44/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 279.0149 - mse: 279.0149\n",
      "Epoch 45/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 278.6133 - mse: 278.6133\n",
      "Epoch 46/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 282.7441 - mse: 282.7441\n",
      "Epoch 47/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 273.7753 - mse: 273.7753\n",
      "Epoch 48/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 277.8284 - mse: 277.8284\n",
      "Epoch 49/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 276.6723 - mse: 276.6723\n",
      "Epoch 50/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 277.5745 - mse: 277.5745\n",
      "Epoch 51/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 275.4406 - mse: 275.4406\n",
      "Epoch 52/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 271.5013 - mse: 271.5013\n",
      "Epoch 53/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 272.3230 - mse: 272.3230\n",
      "Epoch 54/60\n",
      "13/13 [==============================] - 0s 582us/step - loss: 270.5696 - mse: 270.5696\n",
      "Epoch 55/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 288.5280 - mse: 288.5280\n",
      "Epoch 56/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 271.8645 - mse: 271.8645\n",
      "Epoch 57/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 270.8198 - mse: 270.8198\n",
      "Epoch 58/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 272.0529 - mse: 272.0529\n",
      "Epoch 59/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 272.6210 - mse: 272.6210\n",
      "Epoch 60/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 267.8445 - mse: 267.8445\n",
      "4/4 [==============================] - 0s 660us/step - loss: 125.9584 - mse: 125.9584\n",
      "Epoch 1/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 15181.5096 - mse: 15181.5096\n",
      "Epoch 2/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 10744.3611 - mse: 10744.3611\n",
      "Epoch 3/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 1731.0964 - mse: 1731.0964\n",
      "Epoch 4/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 403.7777 - mse: 403.7777\n",
      "Epoch 5/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 273.8082 - mse: 273.8082\n",
      "Epoch 6/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 245.0213 - mse: 245.0213\n",
      "Epoch 7/60\n",
      "13/13 [==============================] - 0s 582us/step - loss: 217.2135 - mse: 217.2135\n",
      "Epoch 8/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 217.2650 - mse: 217.2650\n",
      "Epoch 9/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 214.8112 - mse: 214.8112\n",
      "Epoch 10/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 217.2209 - mse: 217.2209\n",
      "Epoch 11/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.0141 - mse: 218.0141\n",
      "Epoch 12/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.6930 - mse: 218.6930\n",
      "Epoch 13/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 214.5027 - mse: 214.5027\n",
      "Epoch 14/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 214.1646 - mse: 214.1646\n",
      "Epoch 15/60\n",
      "13/13 [==============================] - 0s 582us/step - loss: 214.2245 - mse: 214.2245\n",
      "Epoch 16/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 215.2380 - mse: 215.2380\n",
      "Epoch 17/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 216.3444 - mse: 216.3444\n",
      "Epoch 18/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 219.5660 - mse: 219.5660\n",
      "Epoch 19/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 214.5318 - mse: 214.5318\n",
      "Epoch 20/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.2568 - mse: 209.2568\n",
      "Epoch 21/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.0073 - mse: 218.0073\n",
      "Epoch 22/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 228.4456 - mse: 228.4456\n",
      "Epoch 23/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.2608 - mse: 213.2608\n",
      "Epoch 24/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 208.7421 - mse: 208.7421\n",
      "Epoch 25/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 210.7532 - mse: 210.7532\n",
      "Epoch 26/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.4039 - mse: 211.4039\n",
      "Epoch 27/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 207.3362 - mse: 207.3362\n",
      "Epoch 28/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 210.0347 - mse: 210.0347\n",
      "Epoch 29/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 205.9563 - mse: 205.9563\n",
      "Epoch 30/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 206.8311 - mse: 206.8311\n",
      "Epoch 31/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.6584 - mse: 211.6584\n",
      "Epoch 32/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 210.3364 - mse: 210.3364\n",
      "Epoch 33/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 208.8443 - mse: 208.8443\n",
      "Epoch 34/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.8245 - mse: 209.8245\n",
      "Epoch 35/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 212.5151 - mse: 212.5151\n",
      "Epoch 36/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 207.0868 - mse: 207.0868\n",
      "Epoch 37/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 205.7925 - mse: 205.7925\n",
      "Epoch 38/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.1160 - mse: 209.1160\n",
      "Epoch 39/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.4813 - mse: 209.4813\n",
      "Epoch 40/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 210.1869 - mse: 210.1869\n",
      "Epoch 41/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.1272 - mse: 209.1272\n",
      "Epoch 42/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 208.9661 - mse: 208.9661\n",
      "Epoch 43/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 210.5007 - mse: 210.5007\n",
      "Epoch 44/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.5029 - mse: 211.5029\n",
      "Epoch 45/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 208.8425 - mse: 208.8425\n",
      "Epoch 46/60\n",
      "13/13 [==============================] - 0s 582us/step - loss: 206.4592 - mse: 206.4592\n",
      "Epoch 47/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 205.7867 - mse: 205.7867\n",
      "Epoch 48/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 209.4084 - mse: 209.4084\n",
      "Epoch 49/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.0302 - mse: 209.0302\n",
      "Epoch 50/60\n",
      "13/13 [==============================] - 0s 582us/step - loss: 209.7068 - mse: 209.7068\n",
      "Epoch 51/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 208.1855 - mse: 208.1855\n",
      "Epoch 52/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 207.1604 - mse: 207.1604\n",
      "Epoch 53/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 207.8286 - mse: 207.8286\n",
      "Epoch 54/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.8368 - mse: 211.8368\n",
      "Epoch 55/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 210.3922 - mse: 210.3922\n",
      "Epoch 56/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 204.7999 - mse: 204.7999\n",
      "Epoch 57/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 207.4564 - mse: 207.4564\n",
      "Epoch 58/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 208.4472 - mse: 208.4472\n",
      "Epoch 59/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 207.6559 - mse: 207.6559\n",
      "Epoch 60/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 210.1010 - mse: 210.1010\n",
      "4/4 [==============================] - 0s 998us/step - loss: 245.5515 - mse: 245.5515\n",
      "Epoch 1/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 17180.3296 - mse: 17180.3296\n",
      "Epoch 2/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 8932.9975 - mse: 8932.9975\n",
      "Epoch 3/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 988.3781 - mse: 988.3781\n",
      "Epoch 4/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 449.8517 - mse: 449.8517\n",
      "Epoch 5/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 264.2509 - mse: 264.2509\n",
      "Epoch 6/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 241.3377 - mse: 241.3377\n",
      "Epoch 7/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 217.9715 - mse: 217.9715\n",
      "Epoch 8/60\n",
      "13/13 [==============================] - 0s 582us/step - loss: 218.6591 - mse: 218.6591\n",
      "Epoch 9/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 214.0270 - mse: 214.0270\n",
      "Epoch 10/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 227.5455 - mse: 227.5455\n",
      "Epoch 11/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 216.9339 - mse: 216.9339\n",
      "Epoch 12/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 220.1759 - mse: 220.1759\n",
      "Epoch 13/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 264.4189 - mse: 264.4189\n",
      "Epoch 14/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 228.4031 - mse: 228.4031\n",
      "Epoch 15/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 227.9700 - mse: 227.9700\n",
      "Epoch 16/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 273.1452 - mse: 273.1452\n",
      "Epoch 17/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 322.3066 - mse: 322.3066\n",
      "Epoch 18/60\n",
      "13/13 [==============================] - 0s 582us/step - loss: 218.7574 - mse: 218.7574\n",
      "Epoch 19/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 234.4238 - mse: 234.4238\n",
      "Epoch 20/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 224.4476 - mse: 224.4476\n",
      "Epoch 21/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 231.2090 - mse: 231.2090\n",
      "Epoch 22/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 215.7975 - mse: 215.7975\n",
      "Epoch 23/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 210.6942 - mse: 210.6942\n",
      "Epoch 24/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 215.9033 - mse: 215.9033\n",
      "Epoch 25/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 214.5215 - mse: 214.5215\n",
      "Epoch 26/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 265.9793 - mse: 265.9793\n",
      "Epoch 27/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 215.4315 - mse: 215.4315\n",
      "Epoch 28/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 224.8688 - mse: 224.8688\n",
      "Epoch 29/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 217.8788 - mse: 217.8788\n",
      "Epoch 30/60\n",
      "13/13 [==============================] - 0s 582us/step - loss: 221.6243 - mse: 221.6243\n",
      "Epoch 31/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 222.4568 - mse: 222.4568\n",
      "Epoch 32/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 272.7928 - mse: 272.7928\n",
      "Epoch 33/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 226.3523 - mse: 226.3523\n",
      "Epoch 34/60\n",
      "13/13 [==============================] - 0s 582us/step - loss: 227.1452 - mse: 227.1452\n",
      "Epoch 35/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 214.4659 - mse: 214.4659\n",
      "Epoch 36/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 220.6747 - mse: 220.6747\n",
      "Epoch 37/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 250.7383 - mse: 250.7383\n",
      "Epoch 38/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.7719 - mse: 249.7719\n",
      "Epoch 39/60\n",
      "13/13 [==============================] - 0s 582us/step - loss: 227.2825 - mse: 227.2825\n",
      "Epoch 40/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 255.4783 - mse: 255.4783\n",
      "Epoch 41/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 251.2768 - mse: 251.2768\n",
      "Epoch 42/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.5978 - mse: 218.5978\n",
      "Epoch 43/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.7120 - mse: 218.7120\n",
      "Epoch 44/60\n",
      "13/13 [==============================] - 0s 587us/step - loss: 218.1950 - mse: 218.1950\n",
      "Epoch 45/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 212.9481 - mse: 212.9481\n",
      "Epoch 46/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.3685 - mse: 218.3685\n",
      "Epoch 47/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 211.2662 - mse: 211.2662\n",
      "Epoch 48/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 215.5405 - mse: 215.5405\n",
      "Epoch 49/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 220.7254 - mse: 220.7254\n",
      "Epoch 50/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 214.6620 - mse: 214.6620\n",
      "Epoch 51/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 221.8272 - mse: 221.8272\n",
      "Epoch 52/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 220.7442 - mse: 220.7442\n",
      "Epoch 53/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 222.1163 - mse: 222.1163\n",
      "Epoch 54/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 223.3106 - mse: 223.3106\n",
      "Epoch 55/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 250.5934 - mse: 250.5934\n",
      "Epoch 56/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 230.0036 - mse: 230.0036\n",
      "Epoch 57/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 252.9100 - mse: 252.9100\n",
      "Epoch 58/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 233.0585 - mse: 233.0585\n",
      "Epoch 59/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 257.6854 - mse: 257.6854\n",
      "Epoch 60/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 227.0687 - mse: 227.0687\n",
      "4/4 [==============================] - 0s 992us/step - loss: 219.9505 - mse: 219.9505\n",
      "Epoch 1/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 17366.2510 - mse: 17366.2510\n",
      "Epoch 2/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 7322.6482 - mse: 7322.6482\n",
      "Epoch 3/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 1918.4080 - mse: 1918.4080\n",
      "Epoch 4/60\n",
      "13/13 [==============================] - 0s 582us/step - loss: 1148.7220 - mse: 1148.7220\n",
      "Epoch 5/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 459.1343 - mse: 459.1343\n",
      "Epoch 6/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 366.0131 - mse: 366.0131\n",
      "Epoch 7/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 275.6982 - mse: 275.6982\n",
      "Epoch 8/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 246.2026 - mse: 246.2026\n",
      "Epoch 9/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 236.8677 - mse: 236.8677\n",
      "Epoch 10/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 228.3742 - mse: 228.3742\n",
      "Epoch 11/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 250.8503 - mse: 250.8503\n",
      "Epoch 12/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 238.7486 - mse: 238.7486\n",
      "Epoch 13/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 257.7029 - mse: 257.7029\n",
      "Epoch 14/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 228.8679 - mse: 228.8679\n",
      "Epoch 15/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 239.4760 - mse: 239.4760\n",
      "Epoch 16/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 219.4769 - mse: 219.4769\n",
      "Epoch 17/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 219.6710 - mse: 219.6710\n",
      "Epoch 18/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 247.4595 - mse: 247.4595\n",
      "Epoch 19/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 296.0540 - mse: 296.0540\n",
      "Epoch 20/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 232.1814 - mse: 232.1814\n",
      "Epoch 21/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 231.0053 - mse: 231.0053\n",
      "Epoch 22/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 230.7662 - mse: 230.7662\n",
      "Epoch 23/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 259.6422 - mse: 259.6422\n",
      "Epoch 24/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.9098 - mse: 218.9098\n",
      "Epoch 25/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 212.5483 - mse: 212.5483\n",
      "Epoch 26/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.5160 - mse: 213.5160\n",
      "Epoch 27/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 221.9882 - mse: 221.9882\n",
      "Epoch 28/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 272.8753 - mse: 272.8753\n",
      "Epoch 29/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 227.2604 - mse: 227.2604\n",
      "Epoch 30/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 237.0692 - mse: 237.0692\n",
      "Epoch 31/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 217.3582 - mse: 217.3582\n",
      "Epoch 32/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.1047 - mse: 213.1047\n",
      "Epoch 33/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.1162 - mse: 211.1162\n",
      "Epoch 34/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.4215 - mse: 249.4215\n",
      "Epoch 35/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 229.3993 - mse: 229.3993\n",
      "Epoch 36/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 215.0454 - mse: 215.0454\n",
      "Epoch 37/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 216.5615 - mse: 216.5615\n",
      "Epoch 38/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 225.3928 - mse: 225.3928\n",
      "Epoch 39/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.7634 - mse: 213.7634\n",
      "Epoch 40/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.8054 - mse: 213.8054\n",
      "Epoch 41/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 210.3588 - mse: 210.3588\n",
      "Epoch 42/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 213.7089 - mse: 213.7089\n",
      "Epoch 43/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 208.7565 - mse: 208.7565\n",
      "Epoch 44/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.8178 - mse: 213.8178\n",
      "Epoch 45/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 208.5127 - mse: 208.5127\n",
      "Epoch 46/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.0342 - mse: 209.0342\n",
      "Epoch 47/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.6997 - mse: 213.6997\n",
      "Epoch 48/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 226.1297 - mse: 226.1297\n",
      "Epoch 49/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 232.7090 - mse: 232.7090\n",
      "Epoch 50/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.3407 - mse: 213.3407\n",
      "Epoch 51/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 224.0777 - mse: 224.0777\n",
      "Epoch 52/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.3384 - mse: 213.3384\n",
      "Epoch 53/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 253.1399 - mse: 253.1399\n",
      "Epoch 54/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.8254 - mse: 213.8254\n",
      "Epoch 55/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 209.8958 - mse: 209.8958\n",
      "Epoch 56/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.7116 - mse: 213.7116\n",
      "Epoch 57/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 258.5827 - mse: 258.5827\n",
      "Epoch 58/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 215.8869 - mse: 215.8869\n",
      "Epoch 59/60\n",
      "13/13 [==============================] - 0s 748us/step - loss: 214.3669 - mse: 214.3669\n",
      "Epoch 60/60\n",
      "13/13 [==============================] - 0s 665us/step - loss: 228.8489 - mse: 228.8489\n",
      "4/4 [==============================] - 0s 666us/step - loss: 312.7069 - mse: 312.7069\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 17916.0098 - mse: 17916.0098\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 14982.7723 - mse: 14982.7723\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 1072.2362 - mse: 1072.2362\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 313.5908 - mse: 313.5908\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 251.7940 - mse: 251.7940\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 230.0499 - mse: 230.0499\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 224.1582 - mse: 224.1582\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 230.9627 - mse: 230.9627\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 228.6044 - mse: 228.6044\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 226.4582 - mse: 226.4582\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 230.6335 - mse: 230.6335\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 232.5420 - mse: 232.5420\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 228.3398 - mse: 228.3398\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 221.4533 - mse: 221.4533\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 224.4667 - mse: 224.4667\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 239.1519 - mse: 239.1519\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.6589 - mse: 218.6589\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 224.8903 - mse: 224.8903\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 221.5948 - mse: 221.5948\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 217.8881 - mse: 217.8881\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 224.3883 - mse: 224.3883\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 246.0657 - mse: 246.0657\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 219.4076 - mse: 219.4076\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 277.1867 - mse: 277.1867\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 224.2699 - mse: 224.2699\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.9648 - mse: 218.9648\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 216.9680 - mse: 216.9680\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 229.9099 - mse: 229.9099\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 235.4054 - mse: 235.4054\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 215.7498 - mse: 215.7498\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.9203 - mse: 211.9203\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.3641 - mse: 213.3641\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 214.8086 - mse: 214.8086\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 215.9974 - mse: 215.9974\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.7174 - mse: 211.7174\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.1184 - mse: 211.1184\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 232.6811 - mse: 232.6811\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.0929 - mse: 211.0929\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 214.0219 - mse: 214.0219\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 243.4561 - mse: 243.4561\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 222.7498 - mse: 222.7498\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.7724 - mse: 211.7724\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 250.6163 - mse: 250.6163\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 245.8102 - mse: 245.8102\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.4214 - mse: 209.4214\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 206.7442 - mse: 206.7442\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.5512 - mse: 211.5512\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 216.7278 - mse: 216.7278\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 205.1061 - mse: 205.1061\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.2500 - mse: 218.2500\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 204.4701 - mse: 204.4701\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 220.5595 - mse: 220.5595\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 211.6488 - mse: 211.6488\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 207.9410 - mse: 207.9410\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 206.1167 - mse: 206.1167\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 210.0950 - mse: 210.0950\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 219.3314 - mse: 219.3314\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 229.1075 - mse: 229.1075\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 208.7852 - mse: 208.7852\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 223.9243 - mse: 223.9243\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 226.9646 - mse: 226.9646\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 235.8212 - mse: 235.8212\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 210.8091 - mse: 210.8091\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 203.8956 - mse: 203.8956\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 217.1790 - mse: 217.1790\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.6970 - mse: 209.6970\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 204.3295 - mse: 204.3295\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 240.9915 - mse: 240.9915\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 224.2522 - mse: 224.2522\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 210.9094 - mse: 210.9094\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 212.3590 - mse: 212.3590\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 205.7506 - mse: 205.7506\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 206.6077 - mse: 206.6077\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 201.3576 - mse: 201.3576\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 204.6974 - mse: 204.6974\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 204.1982 - mse: 204.1982\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 207.2503 - mse: 207.2503\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 208.5955 - mse: 208.5955\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 215.0100 - mse: 215.0100\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 208.3465 - mse: 208.3465\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 210.3748 - mse: 210.3748\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 221.3608 - mse: 221.3608\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 252.7275 - mse: 252.7275\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.0590 - mse: 211.0590\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 221.9748 - mse: 221.9748\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.4666 - mse: 211.4666\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 205.6934 - mse: 205.6934\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 214.1775 - mse: 214.1775\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 219.2954 - mse: 219.2954\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 203.1499 - mse: 203.1499\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.5812 - mse: 213.5812\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.0630 - mse: 249.0630\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 208.2937 - mse: 208.2937\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 206.7712 - mse: 206.7712\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 215.9098 - mse: 215.9098\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.5128 - mse: 213.5128\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 211.2432 - mse: 211.2432\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.6996 - mse: 209.6996\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 203.9557 - mse: 203.9557\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 204.9636 - mse: 204.9636\n",
      "4/4 [==============================] - 0s 997us/step - loss: 328.7560 - mse: 328.7560\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 23362.5287 - mse: 23362.5287\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 8673.0865 - mse: 8673.0865\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 2451.4653 - mse: 2451.4653\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 1180.2087 - mse: 1180.2087\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 505.0669 - mse: 505.0669\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 327.4899 - mse: 327.4899\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 293.6134 - mse: 293.6134\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 280.2141 - mse: 280.2141\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 289.6785 - mse: 289.6785\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 288.0007 - mse: 288.0007\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 275.6784 - mse: 275.6784\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 260.9313 - mse: 260.9313\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 257.4532 - mse: 257.4532\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 256.1292 - mse: 256.1292\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 253.6844 - mse: 253.6844\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 255.5803 - mse: 255.5803\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 258.7841 - mse: 258.7841\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 268.0190 - mse: 268.0190\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 254.8252 - mse: 254.8252\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 262.2060 - mse: 262.2060\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 262.2889 - mse: 262.2889\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 256.5177 - mse: 256.5177\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 269.9392 - mse: 269.9392\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 290.8027 - mse: 290.8027\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.8586 - mse: 249.8586\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 243.6117 - mse: 243.6117\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 261.8963 - mse: 261.8963\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 292.7517 - mse: 292.7517\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.6296 - mse: 249.6296\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 270.1175 - mse: 270.1175\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 270.0479 - mse: 270.0479\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 302.9503 - mse: 302.9503\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 305.3486 - mse: 305.3486\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.1855 - mse: 249.1855\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 255.1022 - mse: 255.1022\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 288.8729 - mse: 288.8729\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 277.8960 - mse: 277.8960\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 271.1220 - mse: 271.1220\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 247.3350 - mse: 247.3350\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 243.4348 - mse: 243.4348\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 242.8029 - mse: 242.8029\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 239.4486 - mse: 239.4486\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 283.2375 - mse: 283.2375\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 260.1087 - mse: 260.1087\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 243.0655 - mse: 243.0655\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 269.0189 - mse: 269.0189\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 303.4760 - mse: 303.4760\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 289.7853 - mse: 289.7853\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 245.3742 - mse: 245.3742\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 246.7143 - mse: 246.7143\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 273.1207 - mse: 273.1207\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.0821 - mse: 249.0821\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 279.3527 - mse: 279.3527\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 245.6517 - mse: 245.6517\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 275.0549 - mse: 275.0549\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 248.8541 - mse: 248.8541\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 274.8185 - mse: 274.8185\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 248.6693 - mse: 248.6693\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 267.3452 - mse: 267.3452\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 267.5410 - mse: 267.5410\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 251.8561 - mse: 251.8561\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 261.6550 - mse: 261.6550\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 252.3808 - mse: 252.3808\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 258.0906 - mse: 258.0906\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 245.3375 - mse: 245.3375\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 244.1788 - mse: 244.1788\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 261.7739 - mse: 261.7739\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 391.8417 - mse: 391.8417\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 265.1811 - mse: 265.1811\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 243.1867 - mse: 243.1867\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 241.5004 - mse: 241.5004\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 242.6098 - mse: 242.6098\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 246.4144 - mse: 246.4144\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 245.7102 - mse: 245.7102\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 236.2308 - mse: 236.2308\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 240.1861 - mse: 240.1861\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 245.7277 - mse: 245.7277\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 241.5999 - mse: 241.5999\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 240.3474 - mse: 240.3474\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 246.5313 - mse: 246.5313\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 244.4896 - mse: 244.4896\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 266.8597 - mse: 266.8597\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 261.4841 - mse: 261.4841\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 251.4395 - mse: 251.4395\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 243.5992 - mse: 243.5992\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 242.8265 - mse: 242.8265\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 241.1047 - mse: 241.1047\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 253.5775 - mse: 253.5775\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 237.2625 - mse: 237.2625\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 250.7778 - mse: 250.7778\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 240.0689 - mse: 240.0689\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.2781 - mse: 249.2781\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 248.5463 - mse: 248.5463\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 245.4428 - mse: 245.4428\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 251.1055 - mse: 251.1055\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 260.6390 - mse: 260.6390\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.0736 - mse: 249.0736\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 249.5168 - mse: 249.5168\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 250.7080 - mse: 250.7080\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 270.1820 - mse: 270.1820\n",
      "4/4 [==============================] - 0s 660us/step - loss: 235.9856 - mse: 235.9856\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 28340.2102 - mse: 28340.2102\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 17032.7596 - mse: 17032.7589\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 15622.9906 - mse: 15622.9906\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 14228.0349 - mse: 14228.0349\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 12849.9997 - mse: 12849.9997\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 11566.1353 - mse: 11566.1353\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 10406.1283 - mse: 10406.1283\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 9322.2915 - mse: 9322.2915\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 8326.5363 - mse: 8326.5359\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 7411.7980 - mse: 7411.7980\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 6616.0266 - mse: 6616.0266\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 5859.2006 - mse: 5859.2006\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 5172.4754 - mse: 5172.4754\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 4565.0704 - mse: 4565.0704\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 3995.6973 - mse: 3995.6973\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 3514.5782 - mse: 3514.5782\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 3115.2077 - mse: 3115.2077\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 2698.8629 - mse: 2698.8629\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 2363.7706 - mse: 2363.7706\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 2054.3127 - mse: 2054.3127\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 1805.0470 - mse: 1805.0470\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 1574.3732 - mse: 1574.3732\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 1363.5749 - mse: 1363.5749\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 1183.6731 - mse: 1183.6731\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 1038.3039 - mse: 1038.3039\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 913.2471 - mse: 913.2471\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 797.0389 - mse: 797.0389\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 701.4318 - mse: 701.4318\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 618.2307 - mse: 618.2307\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 547.5986 - mse: 547.5986\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 502.5774 - mse: 502.5774\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 447.7062 - mse: 447.7062\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 408.1016 - mse: 408.1016\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 374.8753 - mse: 374.8753\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 349.6715 - mse: 349.6715\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 662us/step - loss: 328.8667 - mse: 328.8667\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 310.6391 - mse: 310.6391\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 294.6827 - mse: 294.6827\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 280.7484 - mse: 280.7484\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 275.0190 - mse: 275.0190\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 263.3968 - mse: 263.3968\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 259.0201 - mse: 259.0201\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 255.2245 - mse: 255.2245\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 250.8178 - mse: 250.8178\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 247.9891 - mse: 247.9891\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 243.6931 - mse: 243.6931\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 241.1215 - mse: 241.1215\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 237.3526 - mse: 237.3526\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 243.6299 - mse: 243.6299\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 240.9758 - mse: 240.9758\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 239.5578 - mse: 239.5578\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 240.1990 - mse: 240.1990\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 239.3318 - mse: 239.3318\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 235.8461 - mse: 235.8461\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 233.6428 - mse: 233.6428\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 234.1609 - mse: 234.1609\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 236.7711 - mse: 236.7711\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 240.7670 - mse: 240.7670\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 238.3664 - mse: 238.3664\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 239.2865 - mse: 239.2865\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 235.8317 - mse: 235.8317\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 236.8567 - mse: 236.8567\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 233.9205 - mse: 233.9205\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 233.0038 - mse: 233.0038\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 238.2519 - mse: 238.2519\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 235.5547 - mse: 235.5547\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 233.4026 - mse: 233.4026\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 236.5676 - mse: 236.5676\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 235.5771 - mse: 235.5771\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 238.5144 - mse: 238.5144\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 236.8934 - mse: 236.8934\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 237.7238 - mse: 237.7238\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 237.2461 - mse: 237.2461\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 234.7690 - mse: 234.7690\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 235.3883 - mse: 235.3883\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 239.4971 - mse: 239.4971\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 236.5208 - mse: 236.5208\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 237.2788 - mse: 237.2788\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 236.3504 - mse: 236.3504\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 234.2345 - mse: 234.2345\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 235.1863 - mse: 235.1863\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 235.1875 - mse: 235.1875\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 232.8994 - mse: 232.8994\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 232.7930 - mse: 232.7930\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 236.7233 - mse: 236.7233\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 234.1760 - mse: 234.1760\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 236.3002 - mse: 236.3002\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 237.2772 - mse: 237.2772\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 237.5295 - mse: 237.5295\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 235.8638 - mse: 235.8638\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 233.3119 - mse: 233.3119\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 235.3315 - mse: 235.3315\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 235.8396 - mse: 235.8396\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 233.9640 - mse: 233.9640\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 236.5278 - mse: 236.5278\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 237.7659 - mse: 237.7659\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 232.2603 - mse: 232.2603\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 234.8003 - mse: 234.8003\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 237.7187 - mse: 237.7187\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 235.2382 - mse: 235.2382\n",
      "4/4 [==============================] - 0s 998us/step - loss: 313.5344 - mse: 313.5344\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 14693.0349 - mse: 14693.0349\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 6610.0601 - mse: 6610.0601\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 2456.0307 - mse: 2456.0307\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 681.3434 - mse: 681.3434\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 335.6638 - mse: 335.6638\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 258.8111 - mse: 258.8111\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 231.5951 - mse: 231.5951\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 227.2054 - mse: 227.2054\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 225.1898 - mse: 225.1898\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 221.0928 - mse: 221.0928\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 219.2188 - mse: 219.2188\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 669us/step - loss: 227.1816 - mse: 227.1816\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 212.2100 - mse: 212.2100\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 215.6852 - mse: 215.6852\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 215.3587 - mse: 215.3587\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.3308 - mse: 218.3308\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 214.6579 - mse: 214.6579\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 216.1471 - mse: 216.1471\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 230.9213 - mse: 230.9213\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.4647 - mse: 218.4647\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 234.6366 - mse: 234.6366\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 221.3572 - mse: 221.3572\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 212.4746 - mse: 212.4746\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 218.8424 - mse: 218.8424\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 790us/step - loss: 219.3242 - mse: 219.3242\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 217.1629 - mse: 217.1629\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 219.4264 - mse: 219.4264\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 221.3743 - mse: 221.3743\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.6882 - mse: 213.6882\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 212.3797 - mse: 212.3797\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.7916 - mse: 213.7916\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 216.5467 - mse: 216.5467\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 212.5234 - mse: 212.5234\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 221.3319 - mse: 221.3319\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 214.1081 - mse: 214.1081\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 227.8535 - mse: 227.8535\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 228.5143 - mse: 228.5143\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.5319 - mse: 213.5319\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 221.4188 - mse: 221.4188\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 215.9248 - mse: 215.9248\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 219.7908 - mse: 219.7908\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 214.1010 - mse: 214.1010\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 216.0430 - mse: 216.0430\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 211.9111 - mse: 211.9111\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 212.7544 - mse: 212.7544\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 219.4471 - mse: 219.4471\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 225.8881 - mse: 225.8881\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 214.9789 - mse: 214.9789\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 224.1506 - mse: 224.1506\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.7430 - mse: 213.7430\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.9808 - mse: 218.9808\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 219.3659 - mse: 219.3659\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 220.9322 - mse: 220.9322\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 259.4121 - mse: 259.4121\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 229.5433 - mse: 229.5433\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 224.2679 - mse: 224.2679\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.5412 - mse: 213.5412\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.8196 - mse: 209.8196\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 213.1936 - mse: 213.1936\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 212.9163 - mse: 212.9163\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 213.0333 - mse: 213.0333\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 212.7601 - mse: 212.7601\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 224.3864 - mse: 224.3864\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 220.2214 - mse: 220.2214\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 220.5139 - mse: 220.5139\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 216.6599 - mse: 216.6599\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 246.4804 - mse: 246.4804\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 236.2255 - mse: 236.2255\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.6755 - mse: 213.6755\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 212.1572 - mse: 212.1572\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 212.9750 - mse: 212.9750\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 221.3634 - mse: 221.3634\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 212.8361 - mse: 212.8361\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 227.3807 - mse: 227.3807\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 210.4419 - mse: 210.4419\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 216.3204 - mse: 216.3204\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 216.3963 - mse: 216.3963\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 217.3078 - mse: 217.3078\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.7169 - mse: 218.7169\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 227.6159 - mse: 227.6159\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 214.3560 - mse: 214.3560\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 217.1381 - mse: 217.1381\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 210.3506 - mse: 210.3506\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 214.4426 - mse: 214.4426\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.1395 - mse: 218.1395\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 208.4801 - mse: 208.4801\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.5090 - mse: 209.5090\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.6692 - mse: 213.6692\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 234.0089 - mse: 234.0089\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.7072 - mse: 209.7072\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.1410 - mse: 218.1410\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 210.3721 - mse: 210.3721\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 238.2625 - mse: 238.2625\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 210.0981 - mse: 210.0981\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 212.9934 - mse: 212.9934\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 209.9185 - mse: 209.9185\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 212.8309 - mse: 212.8309\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 209.9008 - mse: 209.9008\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 233.8863 - mse: 233.8863\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.4175 - mse: 209.4175\n",
      "4/4 [==============================] - 0s 665us/step - loss: 246.2109 - mse: 246.2109\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 12928.6543 - mse: 12928.6543\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 2523.1101 - mse: 2523.1101\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 520.5995 - mse: 520.5995\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 300.5796 - mse: 300.5796\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 257.0264 - mse: 257.0264\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 227.5005 - mse: 227.5005\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 227.4680 - mse: 227.4680\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 227.8375 - mse: 227.8375\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 241.5928 - mse: 241.5928\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 831us/step - loss: 239.7996 - mse: 239.7996\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 707us/step - loss: 237.9239 - mse: 237.9239\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 240.6738 - mse: 240.6738\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 998us/step - loss: 225.7105 - mse: 225.7105\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 219.8310 - mse: 219.8310\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 831us/step - loss: 222.3350 - mse: 222.3350\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 230.0881 - mse: 230.0881\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 831us/step - loss: 234.6411 - mse: 234.6411\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 236.1103 - mse: 236.1103\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 223.1301 - mse: 223.1301\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 228.8584 - mse: 228.8584\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.5058 - mse: 218.5058\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 241.3598 - mse: 241.3598\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 252.1983 - mse: 252.1983\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 232.3810 - mse: 232.3810\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 226.4987 - mse: 226.4987\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 220.4132 - mse: 220.4132\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 231.3390 - mse: 231.3390\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.5987 - mse: 218.5987\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 237.0809 - mse: 237.0809\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 238.6548 - mse: 238.6548\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 227.0573 - mse: 227.0573\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 232.4732 - mse: 232.4732\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 215.3899 - mse: 215.3899\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 401.1631 - mse: 401.1631\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 260.0626 - mse: 260.0626\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 258.0467 - mse: 258.0467\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 214.3927 - mse: 214.3927\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 224.5624 - mse: 224.5624\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 222.2978 - mse: 222.2978\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 224.5163 - mse: 224.5163\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 320.9566 - mse: 320.9566\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 244.2990 - mse: 244.2990\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 284.6022 - mse: 284.6022\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 240.2412 - mse: 240.2412\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 252.5703 - mse: 252.5703\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 291.1871 - mse: 291.1871\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 231.0274 - mse: 231.0274\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 224.5776 - mse: 224.5776\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 233.3601 - mse: 233.3601\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 232.6981 - mse: 232.6981\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 217.6329 - mse: 217.6329\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 219.4409 - mse: 219.4409\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 224.4866 - mse: 224.4866\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 217.6134 - mse: 217.6134\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 221.2527 - mse: 221.2527\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.2148 - mse: 211.2148\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 241.0800 - mse: 241.0800\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 214.4329 - mse: 214.4329\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 205.9857 - mse: 205.9857\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 243.9625 - mse: 243.9625\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.7982 - mse: 213.7982\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 252.2731 - mse: 252.2731\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 296.2606 - mse: 296.2606\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.8093 - mse: 218.8093\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 226.6319 - mse: 226.6319\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.9215 - mse: 211.9215\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 225.7751 - mse: 225.7751\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 208.9561 - mse: 208.9561\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 227.6581 - mse: 227.6581\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.7669 - mse: 218.7669\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 1173.3868 - mse: 1173.3868\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 469.3731 - mse: 469.3731\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 257.0835 - mse: 257.0835\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 223.8181 - mse: 223.8181\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 218.7402 - mse: 218.7402\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 582us/step - loss: 230.4522 - mse: 230.4522\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 216.3162 - mse: 216.3162\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 208.7534 - mse: 208.7534\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.9847 - mse: 209.9847\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 204.7596 - mse: 204.7596\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 208.4619 - mse: 208.4619\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 219.5710 - mse: 219.5710\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 213.8161 - mse: 213.8161\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 209.4112 - mse: 209.4112\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 208.2238 - mse: 208.2238\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 206.1750 - mse: 206.1750\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.9598 - mse: 211.9598\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.6761 - mse: 211.6761\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.3599 - mse: 211.3599\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 207.7840 - mse: 207.7840\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.6297 - mse: 209.6297\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 207.5584 - mse: 207.5584\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 748us/step - loss: 214.0133 - mse: 214.0133\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.2286 - mse: 211.2286\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 208.9575 - mse: 208.9575\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 211.6582 - mse: 211.6582\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 209.1240 - mse: 209.1240\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 204.8204 - mse: 204.8204\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 206.7564 - mse: 206.7564\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 665us/step - loss: 204.9693 - mse: 204.9693\n",
      "4/4 [==============================] - 0s 665us/step - loss: 283.2892 - mse: 283.2892\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 16003.8724 - mse: 16003.8724\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 15055.1475 - mse: 15055.1475\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 998us/step - loss: 14250.7049 - mse: 14250.7049\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 6750.6921 - mse: 6750.6921\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3722.8776 - mse: 3722.8776\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3983.1486 - mse: 3983.1486\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 998us/step - loss: 1098.6335 - mse: 1098.6335\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 720.6646 - mse: 720.6646\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 998us/step - loss: 568.3921 - mse: 568.3921\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 456.3902 - mse: 456.3902\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 471.1277 - mse: 471.1277\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 19010.2095 - mse: 19010.2095\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 12235.8346 - mse: 12235.8346\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 17367.0973 - mse: 17367.0973\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 953us/step - loss: 17185.3669 - mse: 17185.3669\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 16538.4196 - mse: 16538.4196\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 15459.0908 - mse: 15459.0908\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 14049.2993 - mse: 14049.2993\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 12164.0072 - mse: 12164.0072\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9422.1496 - mse: 9422.1496\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5970.2902 - mse: 5970.2902\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2396.4368 - mse: 2396.4368\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 15019.9590 - mse: 15019.9590\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2411.6714 - mse: 2411.6714\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 748us/step - loss: 761.0613 - mse: 761.0613\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 748us/step - loss: 521.3855 - mse: 521.3855\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 299.0940 - mse: 299.0940\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 350.5487 - mse: 350.5487\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 327.0972 - mse: 327.0972\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 254.8431 - mse: 254.8431\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 998us/step - loss: 392.4799 - mse: 392.4799\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 998us/step - loss: 297.4095 - mse: 297.4095\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EB527160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 996us/step - loss: 414.0646 - mse: 414.0646\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 15592.6366 - mse: 15592.6356\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 15131.7949 - mse: 15131.7949\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 12828.4696 - mse: 12828.4696\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7675.6455 - mse: 7675.6455\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2579.5886 - mse: 2579.5886\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2525.8735 - mse: 2525.8735\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1310.2858 - mse: 1310.2858\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 656.6988 - mse: 656.6988\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 998us/step - loss: 541.1455 - mse: 541.1455\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 514.2110 - mse: 514.2110\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EDFD7C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 544.1000 - mse: 544.1000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 998us/step - loss: 16246.7240 - mse: 16246.7222\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 12663.2513 - mse: 12663.2513\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 8494.7033 - mse: 8494.7033\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 5048.3455 - mse: 5048.3455\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1964.6371 - mse: 1964.6371\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1025.8771 - mse: 1025.8771\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 568.3782 - mse: 568.3782\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 563.1498 - mse: 563.1498\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 997us/step - loss: 439.7913 - mse: 439.7913\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 998us/step - loss: 309.7730 - mse: 309.7730\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7ECCD9790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 998us/step - loss: 318.1136 - mse: 318.1136\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 30411.6440 - mse: 30411.6439\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 17325.2656 - mse: 17325.2646\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 17607.8385 - mse: 17607.8372\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 17289.1602 - mse: 17289.1602\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 16587.6322 - mse: 16587.6322\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 15904.0326 - mse: 15904.0326\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 15311.9427 - mse: 15311.9427\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 14758.5405 - mse: 14758.5405\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 14170.4787 - mse: 14170.4787\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 13610.3571 - mse: 13610.3571\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 13098.6497 - mse: 13098.6497\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 12628.1082 - mse: 12628.1082\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 12102.1953 - mse: 12102.1953\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 11595.9832 - mse: 11595.9832\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 11144.2139 - mse: 11144.2139\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 10688.6423 - mse: 10688.6431\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 10240.8657 - mse: 10240.8657\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9797.6797 - mse: 9797.6797\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 9383.8729 - mse: 9383.8729\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 8986.9575 - mse: 8986.9575\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8612.4285 - mse: 8612.4284\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 8215.9797 - mse: 8215.9797\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 7862.4138 - mse: 7862.4138\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 748us/step - loss: 7511.1296 - mse: 7511.1296\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 7185.3113 - mse: 7185.3113\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 6868.2503 - mse: 6868.2503\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 6552.1820 - mse: 6552.1820\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6282.6117 - mse: 6282.6117\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5963.4982 - mse: 5963.4982\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 5673.6073 - mse: 5673.6073\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5440.0081 - mse: 5440.0081\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 5176.9201 - mse: 5176.9201\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 4926.2063 - mse: 4926.2063\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 4688.6910 - mse: 4688.6910\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 4473.2804 - mse: 4473.2804\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 4227.9408 - mse: 4227.9408\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 4023.8133 - mse: 4023.8133\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3850.6357 - mse: 3850.6357\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3651.9435 - mse: 3651.9435\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 3479.2735 - mse: 3479.2735\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3297.2193 - mse: 3297.2193\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3128.8566 - mse: 3128.8566\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2965.2903 - mse: 2965.2903\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2822.2159 - mse: 2822.2159\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 2691.4390 - mse: 2691.4390\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 2527.4095 - mse: 2527.4095\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2405.5780 - mse: 2405.5780\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2288.7802 - mse: 2288.7802\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2182.0626 - mse: 2182.0626\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2061.2927 - mse: 2061.2927\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EE287310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2261.2800 - mse: 2261.2803\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 26265.8797 - mse: 26265.8797\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 11428.6514 - mse: 11428.6514\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 17776.0889 - mse: 17776.0889\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 17550.9714 - mse: 17550.9714\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 16935.3656 - mse: 16935.3643\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 16370.1541 - mse: 16370.1520\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 15733.3905 - mse: 15733.3905\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 14990.8813 - mse: 14990.8813\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 14245.1880 - mse: 14245.1880\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 13322.0929 - mse: 13322.0929\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 12211.2222 - mse: 12211.2222\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 10689.0762 - mse: 10689.0762\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 877us/step - loss: 8675.8128 - mse: 8675.8130\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 995us/step - loss: 6159.1880 - mse: 6159.1880\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 871us/step - loss: 3467.3795 - mse: 3467.3795\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1279.9168 - mse: 1279.9166\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 333.7915 - mse: 333.7915\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 473.9369 - mse: 473.9369\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 671.2416 - mse: 671.2416\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 509.2774 - mse: 509.2774\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 323.5440 - mse: 323.5440\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 284.1963 - mse: 284.1963\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 310.8648 - mse: 310.8648\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 318.3093 - mse: 318.3093\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 296.9958 - mse: 296.9958\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 284.3750 - mse: 284.3750\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 283.6172 - mse: 283.6172\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 283.3796 - mse: 283.3796\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 283.4655 - mse: 283.4655\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 281.4597 - mse: 281.4597\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 284.3225 - mse: 284.3225\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 283.9676 - mse: 283.9676\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 281.2273 - mse: 281.2273\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 282.0264 - mse: 282.0264\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 282.5766 - mse: 282.5766\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 282.2115 - mse: 282.2115\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 281.8223 - mse: 281.8223\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 283.4413 - mse: 283.4413\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 282.6478 - mse: 282.6478\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 281.5868 - mse: 281.5868\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 993us/step - loss: 282.7857 - mse: 282.7857\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 281.7081 - mse: 281.7081\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 284.9107 - mse: 284.9107\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 279.7642 - mse: 279.7642\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 282.6236 - mse: 282.6236\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 283.9058 - mse: 283.9058\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 279.4103 - mse: 279.4103\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 279.7936 - mse: 279.7936\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 283.0403 - mse: 283.0403\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 281.3294 - mse: 281.3294\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7ECB47CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 131.1657 - mse: 131.1657\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 12199.5052 - mse: 12199.5052\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 626.6866 - mse: 626.6866\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 583.4930 - mse: 583.4930\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 648.3107 - mse: 648.3107\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 402.4711 - mse: 402.4711\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 427.1473 - mse: 427.1473\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 309.3195 - mse: 309.3195\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 293.9102 - mse: 293.9102\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 234.7599 - mse: 234.7599\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 264.8388 - mse: 264.8388\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 243.7967 - mse: 243.7967\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 237.9610 - mse: 237.9610\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 223.2503 - mse: 223.2503\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 214.2442 - mse: 214.2442\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 285.3271 - mse: 285.3271\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 448.6016 - mse: 448.6016\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 332.1883 - mse: 332.1883\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 251.2498 - mse: 251.2498\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 245.7656 - mse: 245.7656\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 350.7975 - mse: 350.7975\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 280.2399 - mse: 280.2399\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 249.1123 - mse: 249.1123\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 346.6543 - mse: 346.6543\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 748us/step - loss: 284.7365 - mse: 284.7365\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 237.4939 - mse: 237.4939\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 209.7205 - mse: 209.7205\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 275.1689 - mse: 275.1689\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 254.6921 - mse: 254.6921\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 231.3641 - mse: 231.3641\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 223.5898 - mse: 223.5898\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 224.6658 - mse: 224.6658\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 229.2947 - mse: 229.2947\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 222.5281 - mse: 222.5281\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 748us/step - loss: 221.5980 - mse: 221.5980\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 214.5701 - mse: 214.5701\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 211.6207 - mse: 211.6207\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 216.5838 - mse: 216.5838\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 230.0316 - mse: 230.0316\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 294.1349 - mse: 294.1349\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 235.3204 - mse: 235.3204\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 282.8256 - mse: 282.8256\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 256.2849 - mse: 256.2849\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 232.7298 - mse: 232.7298\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 242.4448 - mse: 242.4448\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 287.0675 - mse: 287.0675\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 343.1875 - mse: 343.1875\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 252.4617 - mse: 252.4617\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 259.5515 - mse: 259.5515\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 227.9891 - mse: 227.9891\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 261.3945 - mse: 261.3945\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EB5273A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 498.5493 - mse: 498.5493\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 15168.6325 - mse: 15168.6326\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 14355.9775 - mse: 14355.9775\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9886.1852 - mse: 9886.1852\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 5337.5406 - mse: 5337.5407\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1966.1555 - mse: 1966.1555\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1027.5637 - mse: 1027.5637\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 859.4918 - mse: 859.4918\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 449.5766 - mse: 449.5766\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 464.8657 - mse: 464.8657\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 311.9044 - mse: 311.9044\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 270.6212 - mse: 270.6212\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 328.8304 - mse: 328.8304\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 254.6712 - mse: 254.6712\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 296.9243 - mse: 296.9243\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 259.5130 - mse: 259.5130\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 239.2443 - mse: 239.2443\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 239.4789 - mse: 239.4789\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 235.4121 - mse: 235.4121\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 243.9388 - mse: 243.9388\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 224.4710 - mse: 224.4710\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 225.0545 - mse: 225.0545\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 220.5506 - mse: 220.5506\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 222.7028 - mse: 222.7028\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 219.2441 - mse: 219.2441\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 214.6596 - mse: 214.6596\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 215.1940 - mse: 215.1940\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 216.5718 - mse: 216.5718\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 223.4825 - mse: 223.4825\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 215.2722 - mse: 215.2722\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 215.5528 - mse: 215.5528\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 748us/step - loss: 233.0517 - mse: 233.0517\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 228.9291 - mse: 228.9291\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 224.3965 - mse: 224.3965\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 212.7790 - mse: 212.7790\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 218.7391 - mse: 218.7391\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 319.3538 - mse: 319.3538\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 252.8696 - mse: 252.8696\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 243.3141 - mse: 243.3141\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 226.7969 - mse: 226.7969\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 218.3334 - mse: 218.3334\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 218.5749 - mse: 218.5749\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 214.4724 - mse: 214.4724\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 217.9714 - mse: 217.9714\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 236.0880 - mse: 236.0880\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 226.7739 - mse: 226.7739\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 222.3203 - mse: 222.3203\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 221.3751 - mse: 221.3751\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 213.3389 - mse: 213.3389\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 219.2893 - mse: 219.2893\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 212.3266 - mse: 212.3266\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EE3CBD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 998us/step - loss: 252.4321 - mse: 252.4321\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 13203.2734 - mse: 13203.2728\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3320.5033 - mse: 3320.5031\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 995.1495 - mse: 995.1494\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 422.8600 - mse: 422.8600\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 413.9106 - mse: 413.9106\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 271.5999 - mse: 271.5999\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 528.0208 - mse: 528.0208\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 354.3641 - mse: 354.3641\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 257.4912 - mse: 257.4912\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 241.9383 - mse: 241.9383\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 291.4071 - mse: 291.4071\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 254.9032 - mse: 254.9032\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 315.5650 - mse: 315.5650\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 249.5237 - mse: 249.5237\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 240.1329 - mse: 240.1329\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 242.1050 - mse: 242.1050\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 267.2953 - mse: 267.2953\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 229.3987 - mse: 229.3987\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 218.2113 - mse: 218.2113\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 230.1904 - mse: 230.1904\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 263.6791 - mse: 263.6791\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 266.4071 - mse: 266.4071\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 275.6953 - mse: 275.6953\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 266.7316 - mse: 266.7316\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 217.4960 - mse: 217.4960\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 258.2499 - mse: 258.2499\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 230.0129 - mse: 230.0129\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 241.1218 - mse: 241.1218\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 271.6876 - mse: 271.6876\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 211.3767 - mse: 211.3767\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 218.9527 - mse: 218.9527\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 219.2599 - mse: 219.2599\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 216.3742 - mse: 216.3742\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 222.3683 - mse: 222.3683\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 227.8859 - mse: 227.8859\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 242.8640 - mse: 242.8640\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 227.9320 - mse: 227.9320\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 233.8898 - mse: 233.8898\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 260.2877 - mse: 260.2877\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 270.0370 - mse: 270.0370\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 236.0530 - mse: 236.0530\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 248.9256 - mse: 248.9256\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 351.3605 - mse: 351.3605\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 232.3838 - mse: 232.3838\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 214.6802 - mse: 214.6802\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 269.1112 - mse: 269.1112\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 274.7460 - mse: 274.7460\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 341.1737 - mse: 341.1737\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 997us/step - loss: 465.7982 - mse: 465.7982\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 998us/step - loss: 259.3277 - mse: 259.3277\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EB4F1EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 997us/step - loss: 469.9495 - mse: 469.9495\n",
      "Epoch 1/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 28439.7205 - mse: 28439.7205\n",
      "Epoch 2/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 17465.0007 - mse: 17465.0007\n",
      "Epoch 3/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 17552.6299 - mse: 17552.6296\n",
      "Epoch 4/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 17113.0234 - mse: 17113.0234\n",
      "Epoch 5/60\n",
      "5/5 [==============================] - 0s 748us/step - loss: 16442.4310 - mse: 16442.4310\n",
      "Epoch 6/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 15799.9411 - mse: 15799.9411\n",
      "Epoch 7/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 15222.7580 - mse: 15222.7580\n",
      "Epoch 8/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 14646.5656 - mse: 14646.5656\n",
      "Epoch 9/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 14114.6030 - mse: 14114.6030\n",
      "Epoch 10/60\n",
      "5/5 [==============================] - 0s 748us/step - loss: 13564.2887 - mse: 13564.2887\n",
      "Epoch 11/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 13006.6691 - mse: 13006.6691\n",
      "Epoch 12/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 12537.0184 - mse: 12537.0184\n",
      "Epoch 13/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 12007.0142 - mse: 12007.0142\n",
      "Epoch 14/60\n",
      "5/5 [==============================] - 0s 748us/step - loss: 11538.6147 - mse: 11538.6147\n",
      "Epoch 15/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 11053.5233 - mse: 11053.5233\n",
      "Epoch 16/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 10617.4108 - mse: 10617.4108\n",
      "Epoch 17/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 10175.2935 - mse: 10175.2935\n",
      "Epoch 18/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 9746.6826 - mse: 9746.6826\n",
      "Epoch 19/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 9320.6201 - mse: 9320.6201\n",
      "Epoch 20/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 8927.4121 - mse: 8927.4121\n",
      "Epoch 21/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8545.3836 - mse: 8545.3836\n",
      "Epoch 22/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8182.0635 - mse: 8182.0635\n",
      "Epoch 23/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7823.1748 - mse: 7823.1748\n",
      "Epoch 24/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 7485.4624 - mse: 7485.4624\n",
      "Epoch 25/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 7170.1964 - mse: 7170.1964\n",
      "Epoch 26/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6833.4843 - mse: 6833.4843\n",
      "Epoch 27/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 6532.5274 - mse: 6532.5274\n",
      "Epoch 28/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 6222.6170 - mse: 6222.6170\n",
      "Epoch 29/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 5941.6830 - mse: 5941.6830\n",
      "Epoch 30/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 5676.0579 - mse: 5676.0579\n",
      "Epoch 31/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 5402.1274 - mse: 5402.1274\n",
      "Epoch 32/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5162.6853 - mse: 5162.6853\n",
      "Epoch 33/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 4903.7551 - mse: 4903.7551\n",
      "Epoch 34/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 4673.3806 - mse: 4673.3802\n",
      "Epoch 35/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 4438.4818 - mse: 4438.4818\n",
      "Epoch 36/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4243.9613 - mse: 4243.9613\n",
      "Epoch 37/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4010.7845 - mse: 4010.7845\n",
      "Epoch 38/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3812.2262 - mse: 3812.2262\n",
      "Epoch 39/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3635.8328 - mse: 3635.8328\n",
      "Epoch 40/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3463.7034 - mse: 3463.7034\n",
      "Epoch 41/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3271.8566 - mse: 3271.8566\n",
      "Epoch 42/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3110.4563 - mse: 3110.4563\n",
      "Epoch 43/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2964.1766 - mse: 2964.1766\n",
      "Epoch 44/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 2806.0198 - mse: 2806.0198\n",
      "Epoch 45/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 2660.4077 - mse: 2660.4077\n",
      "Epoch 46/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2533.7846 - mse: 2533.7845\n",
      "Epoch 47/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2388.8011 - mse: 2388.8011\n",
      "Epoch 48/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 2265.6908 - mse: 2265.6908\n",
      "Epoch 49/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2152.5305 - mse: 2152.5305\n",
      "Epoch 50/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2034.7690 - mse: 2034.7690\n",
      "Epoch 51/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1933.0481 - mse: 1933.0481\n",
      "Epoch 52/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1836.3769 - mse: 1836.3769\n",
      "Epoch 53/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1734.3161 - mse: 1734.3161\n",
      "Epoch 54/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1652.9844 - mse: 1652.9844\n",
      "Epoch 55/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1568.6975 - mse: 1568.6975\n",
      "Epoch 56/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1477.1822 - mse: 1477.1822\n",
      "Epoch 57/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1419.8632 - mse: 1419.8632\n",
      "Epoch 58/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1329.5070 - mse: 1329.5070\n",
      "Epoch 59/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1264.9607 - mse: 1264.9607\n",
      "Epoch 60/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1204.7679 - mse: 1204.7679\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EE287AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 997us/step - loss: 1388.7344 - mse: 1388.7344\n",
      "Epoch 1/60\n",
      "5/5 [==============================] - 0s 994us/step - loss: 14210.4019 - mse: 14210.4020\n",
      "Epoch 2/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 9431.4924 - mse: 9431.4924\n",
      "Epoch 3/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6041.8390 - mse: 6041.8390\n",
      "Epoch 4/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 3941.3927 - mse: 3941.3927\n",
      "Epoch 5/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2205.7035 - mse: 2205.7034\n",
      "Epoch 6/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 762.2375 - mse: 762.2375\n",
      "Epoch 7/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 761.8745 - mse: 761.8745\n",
      "Epoch 8/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 365.6127 - mse: 365.6127\n",
      "Epoch 9/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 295.5926 - mse: 295.5926\n",
      "Epoch 10/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 290.8453 - mse: 290.8453\n",
      "Epoch 11/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 292.5032 - mse: 292.5032\n",
      "Epoch 12/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 259.6886 - mse: 259.6886\n",
      "Epoch 13/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 248.8922 - mse: 248.8922\n",
      "Epoch 14/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 250.2812 - mse: 250.2812\n",
      "Epoch 15/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 248.2305 - mse: 248.2305\n",
      "Epoch 16/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 261.5135 - mse: 261.5135\n",
      "Epoch 17/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 274.2234 - mse: 274.2234\n",
      "Epoch 18/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 269.3417 - mse: 269.3417\n",
      "Epoch 19/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 254.3158 - mse: 254.3158\n",
      "Epoch 20/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 249.5126 - mse: 249.5126\n",
      "Epoch 21/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 253.8478 - mse: 253.8478\n",
      "Epoch 22/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 247.0136 - mse: 247.0136\n",
      "Epoch 23/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 247.8093 - mse: 247.8093\n",
      "Epoch 24/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 253.9433 - mse: 253.9433\n",
      "Epoch 25/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 249.2181 - mse: 249.2181\n",
      "Epoch 26/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 248.6944 - mse: 248.6944\n",
      "Epoch 27/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 249.5959 - mse: 249.5959\n",
      "Epoch 28/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 246.0055 - mse: 246.0055\n",
      "Epoch 29/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 250.1550 - mse: 250.1550\n",
      "Epoch 30/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 249.3245 - mse: 249.3245\n",
      "Epoch 31/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 255.4854 - mse: 255.4854\n",
      "Epoch 32/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 246.6144 - mse: 246.6144\n",
      "Epoch 33/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 250.4682 - mse: 250.4682\n",
      "Epoch 34/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 245.0550 - mse: 245.0550\n",
      "Epoch 35/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 248.5993 - mse: 248.5993\n",
      "Epoch 36/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 253.6689 - mse: 253.6689\n",
      "Epoch 37/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 256.5579 - mse: 256.5579\n",
      "Epoch 38/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 278.7497 - mse: 278.7497\n",
      "Epoch 39/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 272.0675 - mse: 272.0675\n",
      "Epoch 40/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 264.3586 - mse: 264.3586\n",
      "Epoch 41/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 278.2202 - mse: 278.2202\n",
      "Epoch 42/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 258.8767 - mse: 258.8767\n",
      "Epoch 43/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 271.7636 - mse: 271.7636\n",
      "Epoch 44/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 315.4399 - mse: 315.4399\n",
      "Epoch 45/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 267.8046 - mse: 267.8046\n",
      "Epoch 46/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 264.7658 - mse: 264.7658\n",
      "Epoch 47/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 282.4090 - mse: 282.4090\n",
      "Epoch 48/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 260.7661 - mse: 260.7661\n",
      "Epoch 49/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 252.2207 - mse: 252.2207\n",
      "Epoch 50/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 251.3365 - mse: 251.3365\n",
      "Epoch 51/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 256.6419 - mse: 256.6419\n",
      "Epoch 52/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 269.3027 - mse: 269.3027\n",
      "Epoch 53/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 252.5647 - mse: 252.5647\n",
      "Epoch 54/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 251.9320 - mse: 251.9320\n",
      "Epoch 55/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 246.2670 - mse: 246.2670\n",
      "Epoch 56/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 254.5959 - mse: 254.5959\n",
      "Epoch 57/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 249.0075 - mse: 249.0075\n",
      "Epoch 58/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 248.8481 - mse: 248.8481\n",
      "Epoch 59/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 247.1342 - mse: 247.1342\n",
      "Epoch 60/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 245.8351 - mse: 245.8351\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7ECB478B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 998us/step - loss: 105.3691 - mse: 105.3691\n",
      "Epoch 1/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 13058.3774 - mse: 13058.3774\n",
      "Epoch 2/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2105.1917 - mse: 2105.1917\n",
      "Epoch 3/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1037.8295 - mse: 1037.8295\n",
      "Epoch 4/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 516.1550 - mse: 516.1550\n",
      "Epoch 5/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 653.3978 - mse: 653.3978\n",
      "Epoch 6/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 650.8400 - mse: 650.8400\n",
      "Epoch 7/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 396.8088 - mse: 396.8088\n",
      "Epoch 8/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 381.7136 - mse: 381.7136\n",
      "Epoch 9/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 273.6747 - mse: 273.6747\n",
      "Epoch 10/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 252.6914 - mse: 252.6914\n",
      "Epoch 11/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 227.9819 - mse: 227.9819\n",
      "Epoch 12/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 282.9392 - mse: 282.9392\n",
      "Epoch 13/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 244.2788 - mse: 244.2788\n",
      "Epoch 14/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 223.5540 - mse: 223.5540\n",
      "Epoch 15/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 222.1032 - mse: 222.1032\n",
      "Epoch 16/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 213.9444 - mse: 213.9444\n",
      "Epoch 17/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 228.7450 - mse: 228.7450\n",
      "Epoch 18/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 222.4944 - mse: 222.4944\n",
      "Epoch 19/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 215.6263 - mse: 215.6263\n",
      "Epoch 20/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 224.5287 - mse: 224.5287\n",
      "Epoch 21/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 228.5194 - mse: 228.5194\n",
      "Epoch 22/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 242.0964 - mse: 242.0964\n",
      "Epoch 23/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 221.6646 - mse: 221.6646\n",
      "Epoch 24/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 214.5061 - mse: 214.5061\n",
      "Epoch 25/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 220.5353 - mse: 220.5353\n",
      "Epoch 26/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 271.2042 - mse: 271.2042\n",
      "Epoch 27/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 237.0474 - mse: 237.0474\n",
      "Epoch 28/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 304.3875 - mse: 304.3875\n",
      "Epoch 29/60\n",
      "5/5 [==============================] - 0s 995us/step - loss: 237.3502 - mse: 237.3502\n",
      "Epoch 30/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 216.6501 - mse: 216.6501\n",
      "Epoch 31/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 239.7293 - mse: 239.7293\n",
      "Epoch 32/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 220.7793 - mse: 220.7793\n",
      "Epoch 33/60\n",
      "5/5 [==============================] - 0s 996us/step - loss: 217.6368 - mse: 217.6368\n",
      "Epoch 34/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 249.5293 - mse: 249.5293\n",
      "Epoch 35/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 232.1481 - mse: 232.1481\n",
      "Epoch 36/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 217.5553 - mse: 217.5553\n",
      "Epoch 37/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 217.9119 - mse: 217.9119\n",
      "Epoch 38/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 228.9637 - mse: 228.9637\n",
      "Epoch 39/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 224.3875 - mse: 224.3875\n",
      "Epoch 40/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 231.5380 - mse: 231.5380\n",
      "Epoch 41/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 223.7366 - mse: 223.7366\n",
      "Epoch 42/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 227.4132 - mse: 227.4132\n",
      "Epoch 43/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 237.2195 - mse: 237.2195\n",
      "Epoch 44/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 265.2144 - mse: 265.2143\n",
      "Epoch 45/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 223.0948 - mse: 223.0948\n",
      "Epoch 46/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 282.1217 - mse: 282.1217\n",
      "Epoch 47/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 238.8346 - mse: 238.8346\n",
      "Epoch 48/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 221.9101 - mse: 221.9101\n",
      "Epoch 49/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 301.3346 - mse: 301.3346\n",
      "Epoch 50/60\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 243.6505 - mse: 243.6505\n",
      "Epoch 51/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 239.5081 - mse: 239.5081\n",
      "Epoch 52/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 229.4204 - mse: 229.4204\n",
      "Epoch 53/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 220.6028 - mse: 220.6028\n",
      "Epoch 54/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 210.3639 - mse: 210.3639\n",
      "Epoch 55/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 356.8666 - mse: 356.8666\n",
      "Epoch 56/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 317.7000 - mse: 317.7000\n",
      "Epoch 57/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 239.9514 - mse: 239.9514\n",
      "Epoch 58/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 247.3917 - mse: 247.3917\n",
      "Epoch 59/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 248.1338 - mse: 248.1338\n",
      "Epoch 60/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 232.4702 - mse: 232.4702\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EE374D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 997us/step - loss: 252.5205 - mse: 252.5205\n",
      "Epoch 1/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 32094.9751 - mse: 32094.9751\n",
      "Epoch 2/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 17359.7917 - mse: 17359.7917\n",
      "Epoch 3/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 17694.9915 - mse: 17694.9915\n",
      "Epoch 4/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 17233.5179 - mse: 17233.5182\n",
      "Epoch 5/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 16692.4036 - mse: 16692.4036\n",
      "Epoch 6/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 16033.6541 - mse: 16033.6541\n",
      "Epoch 7/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 15469.9642 - mse: 15469.9642\n",
      "Epoch 8/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 14910.6978 - mse: 14910.6978\n",
      "Epoch 9/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 14353.3903 - mse: 14353.3903\n",
      "Epoch 10/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 13809.9740 - mse: 13809.9740\n",
      "Epoch 11/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 13304.8556 - mse: 13304.8556\n",
      "Epoch 12/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 12766.7533 - mse: 12766.7533\n",
      "Epoch 13/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 12256.3241 - mse: 12256.3241\n",
      "Epoch 14/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 11769.4432 - mse: 11769.4432\n",
      "Epoch 15/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 11322.0711 - mse: 11322.0711\n",
      "Epoch 16/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 10831.3109 - mse: 10831.3112\n",
      "Epoch 17/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 10396.5692 - mse: 10396.5692\n",
      "Epoch 18/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9962.7049 - mse: 9962.7049\n",
      "Epoch 19/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9562.9858 - mse: 9562.9863\n",
      "Epoch 20/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9173.1777 - mse: 9173.1774\n",
      "Epoch 21/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 8753.2990 - mse: 8753.2990\n",
      "Epoch 22/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 8385.7391 - mse: 8385.7394\n",
      "Epoch 23/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 8025.7402 - mse: 8025.7402\n",
      "Epoch 24/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 7666.5928 - mse: 7666.5928\n",
      "Epoch 25/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 7325.3763 - mse: 7325.3763\n",
      "Epoch 26/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7035.9119 - mse: 7035.9119\n",
      "Epoch 27/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6697.8302 - mse: 6697.8302\n",
      "Epoch 28/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 6411.4699 - mse: 6411.4699\n",
      "Epoch 29/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 6123.8678 - mse: 6123.8678\n",
      "Epoch 30/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 5841.6440 - mse: 5841.6440\n",
      "Epoch 31/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 5566.3241 - mse: 5566.3241\n",
      "Epoch 32/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 5315.8861 - mse: 5315.8861\n",
      "Epoch 33/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5071.8686 - mse: 5071.8685\n",
      "Epoch 34/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 4823.7783 - mse: 4823.7786\n",
      "Epoch 35/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4602.1862 - mse: 4602.1862\n",
      "Epoch 36/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 4382.9089 - mse: 4382.9089\n",
      "Epoch 37/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4171.7112 - mse: 4171.7112\n",
      "Epoch 38/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3975.2653 - mse: 3975.2653\n",
      "Epoch 39/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3756.2255 - mse: 3756.2255\n",
      "Epoch 40/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3595.7207 - mse: 3595.7207\n",
      "Epoch 41/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3413.7749 - mse: 3413.7749\n",
      "Epoch 42/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3251.3457 - mse: 3251.3457\n",
      "Epoch 43/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3084.4697 - mse: 3084.4697\n",
      "Epoch 44/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2933.4094 - mse: 2933.4094\n",
      "Epoch 45/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2786.1888 - mse: 2786.1888\n",
      "Epoch 46/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 2653.7743 - mse: 2653.7743\n",
      "Epoch 47/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2509.7417 - mse: 2509.7417\n",
      "Epoch 48/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2380.9608 - mse: 2380.9608\n",
      "Epoch 49/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2260.8201 - mse: 2260.8205\n",
      "Epoch 50/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2157.3880 - mse: 2157.3880\n",
      "Epoch 51/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2037.9271 - mse: 2037.9271\n",
      "Epoch 52/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1941.7745 - mse: 1941.7745\n",
      "Epoch 53/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1838.7977 - mse: 1838.7977\n",
      "Epoch 54/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1749.3544 - mse: 1749.3544\n",
      "Epoch 55/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1656.6723 - mse: 1656.6723\n",
      "Epoch 56/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1565.9284 - mse: 1565.9284\n",
      "Epoch 57/60\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1496.4798 - mse: 1496.4798\n",
      "Epoch 58/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1415.1968 - mse: 1415.1968\n",
      "Epoch 59/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1340.2664 - mse: 1340.2663\n",
      "Epoch 60/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1279.6653 - mse: 1279.6654\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EB4CFE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 997us/step - loss: 1278.7347 - mse: 1278.7346\n",
      "Epoch 1/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 29274.5718 - mse: 29274.5718\n",
      "Epoch 2/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 17614.2959 - mse: 17614.2959\n",
      "Epoch 3/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 17970.4613 - mse: 17970.4613\n",
      "Epoch 4/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 17477.4339 - mse: 17477.4333\n",
      "Epoch 5/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 16803.7523 - mse: 16803.7523\n",
      "Epoch 6/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 16273.0827 - mse: 16273.0827\n",
      "Epoch 7/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 15677.0882 - mse: 15677.0882\n",
      "Epoch 8/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 15127.5708 - mse: 15127.5708\n",
      "Epoch 9/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 14565.8493 - mse: 14565.8493\n",
      "Epoch 10/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 14013.7988 - mse: 14013.7988\n",
      "Epoch 11/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 13426.3804 - mse: 13426.3804\n",
      "Epoch 12/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 12933.4049 - mse: 12933.4049\n",
      "Epoch 13/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 12431.5026 - mse: 12431.5026\n",
      "Epoch 14/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 11960.8465 - mse: 11960.8465\n",
      "Epoch 15/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 11478.4642 - mse: 11478.4642\n",
      "Epoch 16/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 11028.3478 - mse: 11028.3478\n",
      "Epoch 17/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 10604.3962 - mse: 10604.3962\n",
      "Epoch 18/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 10107.1201 - mse: 10107.1201\n",
      "Epoch 19/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9717.9163 - mse: 9717.9163\n",
      "Epoch 20/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9303.8172 - mse: 9303.8180\n",
      "Epoch 21/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 8896.4889 - mse: 8896.4889\n",
      "Epoch 22/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 8528.9211 - mse: 8528.9219\n",
      "Epoch 23/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 8158.7302 - mse: 8158.7302\n",
      "Epoch 24/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7790.3105 - mse: 7790.3105\n",
      "Epoch 25/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7463.7503 - mse: 7463.7503\n",
      "Epoch 26/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 7150.7905 - mse: 7150.7905\n",
      "Epoch 27/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6796.5784 - mse: 6796.5784\n",
      "Epoch 28/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6518.9667 - mse: 6518.9667\n",
      "Epoch 29/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6233.7044 - mse: 6233.7044\n",
      "Epoch 30/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5945.8822 - mse: 5945.8822\n",
      "Epoch 31/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 5660.2313 - mse: 5660.2313\n",
      "Epoch 32/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 5411.7650 - mse: 5411.7650\n",
      "Epoch 33/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 5161.7458 - mse: 5161.7458\n",
      "Epoch 34/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4937.7206 - mse: 4937.7206\n",
      "Epoch 35/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4663.8399 - mse: 4663.8402\n",
      "Epoch 36/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 4456.6562 - mse: 4456.6567\n",
      "Epoch 37/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 4244.3822 - mse: 4244.3822\n",
      "Epoch 38/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 4035.9647 - mse: 4035.9647\n",
      "Epoch 39/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3851.9010 - mse: 3851.9010\n",
      "Epoch 40/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3653.0585 - mse: 3653.0585\n",
      "Epoch 41/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3494.4026 - mse: 3494.4026\n",
      "Epoch 42/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 3328.4767 - mse: 3328.4767\n",
      "Epoch 43/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3154.9001 - mse: 3154.9001\n",
      "Epoch 44/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2993.0723 - mse: 2993.0723\n",
      "Epoch 45/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2854.2033 - mse: 2854.2033\n",
      "Epoch 46/60\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 2696.3155 - mse: 2696.3155\n",
      "Epoch 47/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 2561.1316 - mse: 2561.1316\n",
      "Epoch 48/60\n",
      "5/5 [==============================] - 0s 998us/step - loss: 2438.6501 - mse: 2438.6504\n",
      "Epoch 49/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2312.6523 - mse: 2312.6523\n",
      "Epoch 50/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2189.2184 - mse: 2189.2184\n",
      "Epoch 51/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2078.8894 - mse: 2078.8896\n",
      "Epoch 52/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1981.6190 - mse: 1981.6190\n",
      "Epoch 53/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1882.2618 - mse: 1882.2618\n",
      "Epoch 54/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1773.8270 - mse: 1773.8270\n",
      "Epoch 55/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1688.4080 - mse: 1688.4080\n",
      "Epoch 56/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1595.5008 - mse: 1595.5008\n",
      "Epoch 57/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1522.5218 - mse: 1522.5218\n",
      "Epoch 58/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1430.4834 - mse: 1430.4834\n",
      "Epoch 59/60\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1361.0082 - mse: 1361.0082\n",
      "Epoch 60/60\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1297.9845 - mse: 1297.9845\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7ECA634C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 989us/step - loss: 1038.1064 - mse: 1038.1064\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 993us/step - loss: 23769.3641 - mse: 23769.3641\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 16824.9202 - mse: 16824.9202\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 17163.7373 - mse: 17163.7380\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 15009.6696 - mse: 15009.6696\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 6969.5468 - mse: 6969.5468\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5482.2506 - mse: 5482.2506\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2102.7654 - mse: 2102.7657\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1190.8981 - mse: 1190.8981\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 664.9036 - mse: 664.9036\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 319.0599 - mse: 319.0599\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 248.6976 - mse: 248.6976\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 227.7842 - mse: 227.7842\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 223.5866 - mse: 223.5866\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 221.5820 - mse: 221.5820\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 221.5406 - mse: 221.5406\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 220.8853 - mse: 220.8853\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 217.8471 - mse: 217.8471\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 221.0041 - mse: 221.0041\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 217.6653 - mse: 217.6653\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 216.3532 - mse: 216.3532\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 214.6516 - mse: 214.6516\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 213.0635 - mse: 213.0635\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 212.6304 - mse: 212.6304\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 211.6891 - mse: 211.6891\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 213.2761 - mse: 213.2761\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 210.6193 - mse: 210.6193\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 213.8774 - mse: 213.8774\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 209.9159 - mse: 209.9159\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 209.9472 - mse: 209.9472\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 209.4497 - mse: 209.4497\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 211.3799 - mse: 211.3799\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 208.4802 - mse: 208.4802\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 210.4375 - mse: 210.4375\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 207.9652 - mse: 207.9652\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 208.9827 - mse: 208.9827\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 208.5197 - mse: 208.5197\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 210.5953 - mse: 210.5953\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 209.0303 - mse: 209.0303\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 210.0205 - mse: 210.0205\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 208.6925 - mse: 208.6925\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 209.6455 - mse: 209.6455\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 210.7471 - mse: 210.7471\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 209.5467 - mse: 209.5467\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 211.0481 - mse: 211.0481\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 210.0767 - mse: 210.0767\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 207.3247 - mse: 207.3247\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 208.0285 - mse: 208.0285\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 208.3464 - mse: 208.3464\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 209.3611 - mse: 209.3611\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 206.2132 - mse: 206.2132\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 209.3942 - mse: 209.3942\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 209.0758 - mse: 209.0758\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 207.5894 - mse: 207.5894\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 208.7569 - mse: 208.7569\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 208.0386 - mse: 208.0386\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 208.4416 - mse: 208.4416\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 209.7595 - mse: 209.7595\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 207.7213 - mse: 207.7213\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 208.3184 - mse: 208.3184\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 208.4800 - mse: 208.4800\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 207.2714 - mse: 207.2714\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 209.5064 - mse: 209.5064\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 208.5282 - mse: 208.5282\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 208.1018 - mse: 208.1018\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 208.3852 - mse: 208.3852\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 207.5172 - mse: 207.5172\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 210.5366 - mse: 210.5366\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 208.4183 - mse: 208.4183\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 207.2340 - mse: 207.2340\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 206.4044 - mse: 206.4044\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 207.9586 - mse: 207.9586\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 204.9009 - mse: 204.9009\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 205.1611 - mse: 205.1611\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 205.7534 - mse: 205.7534\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 207.2781 - mse: 207.2781\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 208.0440 - mse: 208.0440\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 207.5574 - mse: 207.5574\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 209.8657 - mse: 209.8657\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 210.8971 - mse: 210.8971\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 211.1836 - mse: 211.1836\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 206.4438 - mse: 206.4438\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 208.2328 - mse: 208.2328\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 207.5547 - mse: 207.5547\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 208.2101 - mse: 208.2101\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 207.0985 - mse: 207.0985\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 207.9073 - mse: 207.9073\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 207.1435 - mse: 207.1435\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 206.9936 - mse: 206.9936\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 207.0482 - mse: 207.0482\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 206.5990 - mse: 206.5990\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 206.4313 - mse: 206.4313\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 207.1919 - mse: 207.1919\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 206.7187 - mse: 206.7187\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 207.3259 - mse: 207.3259\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 205.3119 - mse: 205.3119\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 208.8152 - mse: 208.8152\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 205.7181 - mse: 205.7181\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 210.8426 - mse: 210.8426\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 208.8878 - mse: 208.8878\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 213.9300 - mse: 213.9300\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EB527160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 998us/step - loss: 305.1592 - mse: 305.1592\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 21224.0750 - mse: 21224.0750\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 16871.3848 - mse: 16871.3848\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 17616.6396 - mse: 17616.6396\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 17203.6868 - mse: 17203.6865\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 16175.0047 - mse: 16175.0047\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 14858.9504 - mse: 14858.9504\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 12553.1903 - mse: 12553.1903\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8767.0446 - mse: 8767.0446\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3934.4696 - mse: 3934.4696\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 631.7578 - mse: 631.7578\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 892.4742 - mse: 892.4742\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1350.5470 - mse: 1350.5470\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 514.6232 - mse: 514.6232\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 316.3180 - mse: 316.3180\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 461.5783 - mse: 461.5783\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 394.8625 - mse: 394.8625\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 290.7495 - mse: 290.7495\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 315.2747 - mse: 315.2747\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 326.8148 - mse: 326.8148\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 291.3992 - mse: 291.3992\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 292.1656 - mse: 292.1656\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 301.4642 - mse: 301.4642\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 287.8911 - mse: 287.8911\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 282.7782 - mse: 282.7782\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 286.8816 - mse: 286.8816\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 283.2965 - mse: 283.2965\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 282.0138 - mse: 282.0138\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 284.2218 - mse: 284.2218\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 282.3334 - mse: 282.3334\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 280.3801 - mse: 280.3801\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 283.0520 - mse: 283.0520\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 282.2382 - mse: 282.2382\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 283.4122 - mse: 283.4123\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 282.4826 - mse: 282.4826\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 282.5994 - mse: 282.5994\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 281.0754 - mse: 281.0754\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 283.3448 - mse: 283.3448\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 283.0863 - mse: 283.0863\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 284.2631 - mse: 284.2631\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 281.3899 - mse: 281.3899\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 280.2085 - mse: 280.2085\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 283.2774 - mse: 283.2774\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 282.0340 - mse: 282.0340\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 281.8996 - mse: 281.8996\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 283.0323 - mse: 283.0323\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 281.5820 - mse: 281.5820\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 286.8506 - mse: 286.8506\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 287.4781 - mse: 287.4781\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 283.4148 - mse: 283.4148\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 282.4710 - mse: 282.4710\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 280.9553 - mse: 280.9553\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 282.7072 - mse: 282.7072\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 281.7134 - mse: 281.7134\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 281.5656 - mse: 281.5656\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 283.5467 - mse: 283.5467\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 284.7096 - mse: 284.7096\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 280.3476 - mse: 280.3476\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 283.7097 - mse: 283.7097\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 282.5021 - mse: 282.5021\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 283.0223 - mse: 283.0223\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 285.2541 - mse: 285.2541\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 283.2908 - mse: 283.2908\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 281.6160 - mse: 281.6160\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 283.6232 - mse: 283.6232\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 281.8295 - mse: 281.8295\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 283.6307 - mse: 283.6307\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 281.1517 - mse: 281.1517\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 281.8425 - mse: 281.8425\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 283.0070 - mse: 283.0070\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 283.6254 - mse: 283.6254\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 283.5548 - mse: 283.5548\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 283.5697 - mse: 283.5697\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 280.7856 - mse: 280.7856\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 282.3786 - mse: 282.3786\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 282.5977 - mse: 282.5977\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 282.6602 - mse: 282.6602\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 280.8213 - mse: 280.8213\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 281.9031 - mse: 281.9031\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 284.8185 - mse: 284.8185\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 281.9264 - mse: 281.9265\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 284.5216 - mse: 284.5216\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 286.2187 - mse: 286.2187\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 283.0987 - mse: 283.0987\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 283.8083 - mse: 283.8083\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 285.0203 - mse: 285.0203\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 284.6576 - mse: 284.6576\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 289.4152 - mse: 289.4152\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 285.6721 - mse: 285.6721\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 283.6041 - mse: 283.6041\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 280.2062 - mse: 280.2062\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 282.9965 - mse: 282.9965\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 282.7167 - mse: 282.7167\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 281.7191 - mse: 281.7191\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 280.8045 - mse: 280.8045\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 282.3355 - mse: 282.3355\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 285.1047 - mse: 285.1047\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 283.7849 - mse: 283.7850\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 281.5424 - mse: 281.5424\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 283.6771 - mse: 283.6771\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 282.7507 - mse: 282.7507\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EE3743A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 127.3268 - mse: 127.3268\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 15721.9710 - mse: 15721.9710\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 14868.0244 - mse: 14868.0244\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 12722.8893 - mse: 12722.8893\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9399.1906 - mse: 9399.1906\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7478.7945 - mse: 7478.7945\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3778.2481 - mse: 3778.2481\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2445.8499 - mse: 2445.8499\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1584.2321 - mse: 1584.2321\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 829.8424 - mse: 829.8424\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 489.1258 - mse: 489.1258\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 388.0070 - mse: 388.0070\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 316.0696 - mse: 316.0696\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 272.4197 - mse: 272.4197\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 249.3247 - mse: 249.3247\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 252.3902 - mse: 252.3902\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 235.4020 - mse: 235.4020\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 231.8587 - mse: 231.8587\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 244.5810 - mse: 244.5810\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 228.0614 - mse: 228.0614\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 222.9058 - mse: 222.9058\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 226.2063 - mse: 226.2063\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 224.6128 - mse: 224.6128\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 219.3010 - mse: 219.3010\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 222.5392 - mse: 222.5392\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 227.0476 - mse: 227.0476\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 229.5458 - mse: 229.5458\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 236.9003 - mse: 236.9003\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 230.9773 - mse: 230.9773\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 227.2396 - mse: 227.2396\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 229.6426 - mse: 229.6426\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 232.6967 - mse: 232.6967\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 232.9139 - mse: 232.9139\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 225.5434 - mse: 225.5434\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 223.3248 - mse: 223.3248\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 220.7604 - mse: 220.7604\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 218.1319 - mse: 218.1319\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 217.8561 - mse: 217.8561\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 223.2610 - mse: 223.2610\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 279.5011 - mse: 279.5011\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 236.2770 - mse: 236.2770\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 232.0186 - mse: 232.0186\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 222.4223 - mse: 222.4223\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 218.3147 - mse: 218.3147\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 218.2208 - mse: 218.2208\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 217.7170 - mse: 217.7170\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 220.5835 - mse: 220.5835\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 218.9535 - mse: 218.9535\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 224.9833 - mse: 224.9833\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 237.5669 - mse: 237.5669\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 221.1148 - mse: 221.1148\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 216.4277 - mse: 216.4277\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 218.9995 - mse: 218.9995\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 230.6240 - mse: 230.6240\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 220.1074 - mse: 220.1074\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 227.4747 - mse: 227.4747\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 226.8169 - mse: 226.8169\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 224.8241 - mse: 224.8241\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 225.3661 - mse: 225.3661\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 217.6757 - mse: 217.6757\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 219.3149 - mse: 219.3149\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 215.4155 - mse: 215.4155\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 217.4040 - mse: 217.4040\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 221.5666 - mse: 221.5666\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 215.7486 - mse: 215.7486\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 214.0627 - mse: 214.0627\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 215.4006 - mse: 215.4006\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 217.5240 - mse: 217.5240\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 219.2084 - mse: 219.2084\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 246.5420 - mse: 246.5420\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 223.5026 - mse: 223.5026\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 229.8221 - mse: 229.8221\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 223.2710 - mse: 223.2710\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 218.4923 - mse: 218.4923\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 217.1254 - mse: 217.1254\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 219.4558 - mse: 219.4558\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 213.9820 - mse: 213.9820\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 214.9186 - mse: 214.9186\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 216.0824 - mse: 216.0824\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 228.6629 - mse: 228.6629\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 228.1420 - mse: 228.1420\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 225.8650 - mse: 225.8650\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 227.0374 - mse: 227.0374\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 230.0495 - mse: 230.0495\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 227.2638 - mse: 227.2638\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 244.9743 - mse: 244.9743\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 226.6736 - mse: 226.6736\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 214.6286 - mse: 214.6286\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 218.2325 - mse: 218.2325\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 217.6877 - mse: 217.6877\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 218.7951 - mse: 218.7951\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 216.0744 - mse: 216.0744\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 216.5772 - mse: 216.5772\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 231.4431 - mse: 231.4431\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 218.3532 - mse: 218.3532\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 219.5951 - mse: 219.5951\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 216.9661 - mse: 216.9661\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 215.4546 - mse: 215.4546\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 219.6976 - mse: 219.6976\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 218.2436 - mse: 218.2436\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 224.0513 - mse: 224.0513\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EB4F1D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 250.5241 - mse: 250.5241\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 13756.1019 - mse: 13756.1019\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 7911.3522 - mse: 7911.3522\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1782.1647 - mse: 1782.1647\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1430.6089 - mse: 1430.6089\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 787.8244 - mse: 787.8244\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 531.9374 - mse: 531.9374\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 346.6981 - mse: 346.6981\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 379.1040 - mse: 379.1040\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 271.7085 - mse: 271.7085\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 238.0082 - mse: 238.0082\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 251.0046 - mse: 251.0046\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 230.8218 - mse: 230.8218\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 230.0920 - mse: 230.0920\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 225.6631 - mse: 225.6631\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 228.5934 - mse: 228.5934\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 238.8863 - mse: 238.8863\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 259.7121 - mse: 259.7121\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 231.7135 - mse: 231.7135\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 252.4193 - mse: 252.4193\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 225.2667 - mse: 225.2667\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 219.8404 - mse: 219.8404\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 261.0859 - mse: 261.0859\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 244.5050 - mse: 244.5050\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 234.1536 - mse: 234.1536\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 236.5413 - mse: 236.5413\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 239.5125 - mse: 239.5125\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 236.5419 - mse: 236.5419\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 252.0968 - mse: 252.0968\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 232.5869 - mse: 232.5869\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 225.9010 - mse: 225.9010\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 268.2073 - mse: 268.2073\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 354.3085 - mse: 354.3086\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 495.1995 - mse: 495.1995\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 305.6206 - mse: 305.6206\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 298.8001 - mse: 298.8001\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 305.9845 - mse: 305.9845\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 325.7109 - mse: 325.7110\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 290.7466 - mse: 290.7466\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 344.8907 - mse: 344.8907\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 273.0752 - mse: 273.0752\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 242.9887 - mse: 242.9887\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 239.6379 - mse: 239.6379\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 251.7086 - mse: 251.7086\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 228.3183 - mse: 228.3183\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 223.9693 - mse: 223.9693\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 237.0661 - mse: 237.0661\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 229.2732 - mse: 229.2732\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 350.0326 - mse: 350.0326\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 284.6404 - mse: 284.6404\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 238.2902 - mse: 238.2902\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 227.1726 - mse: 227.1726\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 253.8143 - mse: 253.8143\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 287.1688 - mse: 287.1688\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 245.6908 - mse: 245.6908\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 231.1601 - mse: 231.1601\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 230.0310 - mse: 230.0310\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 227.8893 - mse: 227.8893\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 237.5986 - mse: 237.5986\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 226.5588 - mse: 226.5588\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 229.5103 - mse: 229.5103\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 219.9696 - mse: 219.9696\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 221.7282 - mse: 221.7282\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 218.4300 - mse: 218.4300\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 222.5985 - mse: 222.5985\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 227.6441 - mse: 227.6441\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 228.0904 - mse: 228.0904\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 227.4484 - mse: 227.4484\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 246.2907 - mse: 246.2906\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 242.3752 - mse: 242.3752\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 222.5405 - mse: 222.5405\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 227.0166 - mse: 227.0166\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 227.2193 - mse: 227.2193\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 253.8721 - mse: 253.8721\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 248.5675 - mse: 248.5675\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 264.2800 - mse: 264.2800\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 248.0271 - mse: 248.0271\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 243.8846 - mse: 243.8846\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 999us/step - loss: 271.6928 - mse: 271.6928\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 241.5841 - mse: 241.5841\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 229.5062 - mse: 229.5062\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 353.2475 - mse: 353.2475\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 256.1105 - mse: 256.1105\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 241.4383 - mse: 241.4383\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 218.3099 - mse: 218.3099\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 220.2564 - mse: 220.2564\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 224.1556 - mse: 224.1556\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 224.7786 - mse: 224.7786\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 260.2331 - mse: 260.2331\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 225.7070 - mse: 225.7070\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 252.1497 - mse: 252.1497\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 238.4097 - mse: 238.4097\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 231.6009 - mse: 231.6009\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 236.6856 - mse: 236.6856\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 218.3377 - mse: 218.3377\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 229.9877 - mse: 229.9877\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 228.1670 - mse: 228.1670\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 239.0213 - mse: 239.0213\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 217.8628 - mse: 217.8628\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 228.0130 - mse: 228.0130\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 218.0450 - mse: 218.0450\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EB527160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 225.4953 - mse: 225.4953\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 20101.1128 - mse: 20101.1128\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 16798.2988 - mse: 16798.2988\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 996us/step - loss: 17446.7956 - mse: 17446.7956\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 17114.3581 - mse: 17114.3581\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 16071.4193 - mse: 16071.4193\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 14334.5153 - mse: 14334.5153\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 11543.4198 - mse: 11543.4193\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7016.1935 - mse: 7016.1935\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1999.1354 - mse: 1999.1354\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 446.5627 - mse: 446.5627\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1634.2598 - mse: 1634.2598\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 807.4279 - mse: 807.4279\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 273.1926 - mse: 273.1926\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 476.9298 - mse: 476.9298\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 424.7409 - mse: 424.7409\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 260.0048 - mse: 260.0048\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 293.4220 - mse: 293.4220\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 302.8674 - mse: 302.8673\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 254.2226 - mse: 254.2226\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 256.2589 - mse: 256.2590\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 258.7352 - mse: 258.7352\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 252.1983 - mse: 252.1983\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 252.2086 - mse: 252.2086\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 250.3983 - mse: 250.3983\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 250.5132 - mse: 250.5132\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 248.6595 - mse: 248.6595\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 246.8160 - mse: 246.8160\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 248.6831 - mse: 248.6831\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 247.9871 - mse: 247.9871\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 252.3952 - mse: 252.3952\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 248.0898 - mse: 248.0898\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 248.6510 - mse: 248.6510\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 248.6803 - mse: 248.6803\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 250.4624 - mse: 250.4624\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 251.6048 - mse: 251.6048\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 250.1168 - mse: 250.1168\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 250.8935 - mse: 250.8935\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 247.5684 - mse: 247.5684\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 249.7030 - mse: 249.7030\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 247.4220 - mse: 247.4220\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 249.9097 - mse: 249.9097\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 247.4035 - mse: 247.4035\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 248.4454 - mse: 248.4454\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 249.6250 - mse: 249.6250\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 250.6451 - mse: 250.6451\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 248.1747 - mse: 248.1747\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 249.8029 - mse: 249.8029\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 247.3660 - mse: 247.3660\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 248.5482 - mse: 248.5482\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 248.7188 - mse: 248.7188\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 250.1454 - mse: 250.1454\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 250.1760 - mse: 250.1760\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 248.8874 - mse: 248.8874\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 249.2881 - mse: 249.2881\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 248.1914 - mse: 248.1914\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 247.8460 - mse: 247.8460\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 246.9185 - mse: 246.9185\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 249.5784 - mse: 249.5784\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 251.9301 - mse: 251.9301\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 248.4010 - mse: 248.4010\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 250.4602 - mse: 250.4602\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 253.1362 - mse: 253.1362\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 251.9285 - mse: 251.9285\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 249.3031 - mse: 249.3031\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 248.2531 - mse: 248.2531\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 247.1485 - mse: 247.1485\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 250.4302 - mse: 250.4302\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 247.6205 - mse: 247.6205\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 248.1632 - mse: 248.1632\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 247.1433 - mse: 247.1433\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 249.3793 - mse: 249.3793\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 250.4261 - mse: 250.4261\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 251.2225 - mse: 251.2225\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 249.4821 - mse: 249.4821\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 249.3366 - mse: 249.3366\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 251.2504 - mse: 251.2504\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 247.5154 - mse: 247.5154\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 248.0249 - mse: 248.0249\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 248.2616 - mse: 248.2616\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 249.0698 - mse: 249.0698\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 250.0445 - mse: 250.0445\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 251.9323 - mse: 251.9323\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 250.1307 - mse: 250.1307\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 248.9481 - mse: 248.9481\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 247.1425 - mse: 247.1425\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 248.2143 - mse: 248.2143\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 250.0965 - mse: 250.0965\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 247.8447 - mse: 247.8447\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 249.5626 - mse: 249.5626\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 248.7433 - mse: 248.7433\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 251.5190 - mse: 251.5190\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 249.5764 - mse: 249.5764\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 250.0057 - mse: 250.0057\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 248.9114 - mse: 248.9114\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 250.8658 - mse: 250.8658\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 248.2724 - mse: 248.2724\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 253.3450 - mse: 253.3450\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 249.6799 - mse: 249.6799\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 251.4437 - mse: 251.4437\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 248.3914 - mse: 248.3914\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7ECA63790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 997us/step - loss: 263.6273 - mse: 263.6273\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16166.7844 - mse: 16166.7844\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5835.7644 - mse: 5835.7644\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6427.6248 - mse: 6427.6248\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3951.0093 - mse: 3951.0093\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4049.6888 - mse: 4049.6888\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4692.4816 - mse: 4692.4816\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3170.3871 - mse: 3170.3871\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2655.6826 - mse: 2655.6827\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1882.8794 - mse: 1882.8794\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1346.7711 - mse: 1346.7711\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7ECB474C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1689.9431 - mse: 1689.9431\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 19240.5933 - mse: 19240.5933\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6988.6207 - mse: 6988.6207\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 17610.5923 - mse: 17610.5923\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 17875.0947 - mse: 17875.0947\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 17890.7808 - mse: 17890.7808\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 17785.5938 - mse: 17785.5938\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 17515.2627 - mse: 17515.2627\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 17041.5894 - mse: 17041.5894\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16572.8047 - mse: 16572.8047\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16077.7107 - mse: 16077.7107\n",
      "WARNING:tensorflow:7 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7ECCD9310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 14222.2256 - mse: 14222.2256\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 15128.9707 - mse: 15128.9707\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2040.1717 - mse: 2040.1717\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 830.2370 - mse: 830.2370\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 559.2583 - mse: 559.2583\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 409.4489 - mse: 409.4489\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 440.7944 - mse: 440.7944\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 302.3138 - mse: 302.3138\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 316.3315 - mse: 316.3315\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 265.4399 - mse: 265.4399\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 245.7956 - mse: 245.7956\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7ECA635E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 300.5927 - mse: 300.5927\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16403.7664 - mse: 16403.7664\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7153.7154 - mse: 7153.7154\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16490.4348 - mse: 16490.4348\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16921.3887 - mse: 16921.3892\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16682.1865 - mse: 16682.1865\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16225.5583 - mse: 16225.5583\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 15455.1777 - mse: 15455.1777\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 14205.8289 - mse: 14205.8289\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 12360.6091 - mse: 12360.6091\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9739.8735 - mse: 9739.8735\n",
      "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7E51B43A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 7040.2954 - mse: 7040.2954\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 16699.5786 - mse: 16699.5786\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 23202.1055 - mse: 23202.1055\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 12681.1282 - mse: 12681.1282\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 14686.1770 - mse: 14686.1770\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 13521.4290 - mse: 13521.4290\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 9410.5974 - mse: 9410.5974\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5487.1046 - mse: 5487.1046\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2201.0751 - mse: 2201.0750\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1379.6577 - mse: 1379.6577\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2059.4219 - mse: 2059.4219\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EE42DD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1724.9808 - mse: 1724.9808\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 15805.5063 - mse: 15805.5073\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 15841.4028 - mse: 15841.4028\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 13677.3845 - mse: 13677.3845\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 14186.4678 - mse: 14186.4678\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 11155.1860 - mse: 11155.1860\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4544.4250 - mse: 4544.4250\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4628.4606 - mse: 4628.4606\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1335.8035 - mse: 1335.8035\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2026.3443 - mse: 2026.3443\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 968.3891 - mse: 968.3891\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 703.2875 - mse: 703.2875\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 793.9037 - mse: 793.9037\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 331.4512 - mse: 331.4512\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 330.0964 - mse: 330.0964\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 344.4759 - mse: 344.4759\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 297.5190 - mse: 297.5190\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 276.0713 - mse: 276.0713\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 250.9646 - mse: 250.9646\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 252.6421 - mse: 252.6421\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 247.8687 - mse: 247.8687\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 240.4405 - mse: 240.4405\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 233.5247 - mse: 233.5247\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 226.3802 - mse: 226.3802\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 223.2739 - mse: 223.2739\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 224.0502 - mse: 224.0502\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 221.9795 - mse: 221.9795\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 219.8229 - mse: 219.8229\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 217.4491 - mse: 217.4491\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 218.5296 - mse: 218.5296\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 215.8687 - mse: 215.8687\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 216.6907 - mse: 216.6907\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 214.3565 - mse: 214.3565\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 996us/step - loss: 213.8898 - mse: 213.8898\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 213.0485 - mse: 213.0485\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 211.8703 - mse: 211.8703\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.1803 - mse: 211.1803\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 212.2786 - mse: 212.2786\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 209.9063 - mse: 209.9063\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 209.9043 - mse: 209.9043\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 209.9687 - mse: 209.9687\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 208.1534 - mse: 208.1534\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 209.1816 - mse: 209.1816\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 208.9322 - mse: 208.9322\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 206.7729 - mse: 206.7729\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 206.4791 - mse: 206.4791\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 207.7154 - mse: 207.7154\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 206.4427 - mse: 206.4427\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 205.5102 - mse: 205.5102\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 207.1885 - mse: 207.1885\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 205.6074 - mse: 205.6074\n",
      "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7ECA635E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 299.7654 - mse: 299.7654\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 17325.4141 - mse: 17325.4141\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5471.1472 - mse: 5471.1472\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2791.7105 - mse: 2791.7105\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1303.6497 - mse: 1303.6497\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1205.9572 - mse: 1205.9572\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 696.0405 - mse: 696.0405\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 628.8236 - mse: 628.8236\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 537.7613 - mse: 537.7613\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 327.6058 - mse: 327.6058\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 408.9487 - mse: 408.9487\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 307.5302 - mse: 307.5302\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 309.5682 - mse: 309.5682\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 307.2096 - mse: 307.2096\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 269.9758 - mse: 269.9758\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 274.3508 - mse: 274.3508\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 264.9833 - mse: 264.9833\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 249.1971 - mse: 249.1971\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 254.8483 - mse: 254.8483\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 251.6415 - mse: 251.6415\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 249.8618 - mse: 249.8618\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 254.7715 - mse: 254.7715\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 248.7981 - mse: 248.7981\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 248.2117 - mse: 248.2117\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 247.0643 - mse: 247.0643\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 244.6588 - mse: 244.6588\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 243.8658 - mse: 243.8658\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 245.0713 - mse: 245.0713\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 245.5205 - mse: 245.5205\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 997us/step - loss: 242.2677 - mse: 242.2677\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 243.1310 - mse: 243.1310\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 243.1757 - mse: 243.1757\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 240.3483 - mse: 240.3483\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 240.4733 - mse: 240.4733\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 240.9636 - mse: 240.9636\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 241.2194 - mse: 241.2194\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 240.3972 - mse: 240.3972\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 240.0860 - mse: 240.0860\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 242.3247 - mse: 242.3247\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 240.5859 - mse: 240.5859\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 240.6760 - mse: 240.6760\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 240.8423 - mse: 240.8423\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 240.1023 - mse: 240.1023\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 240.0488 - mse: 240.0488\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 240.5529 - mse: 240.5529\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 239.0207 - mse: 239.0207\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 240.9226 - mse: 240.9226\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 239.0057 - mse: 239.0057\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 239.9978 - mse: 239.9978\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 239.8899 - mse: 239.8899\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 996us/step - loss: 239.7966 - mse: 239.7966\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EB527B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 107.6995 - mse: 107.6995\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 15202.9531 - mse: 15202.9531\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4842.1244 - mse: 4842.1240\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3274.6360 - mse: 3274.6360\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2580.0338 - mse: 2580.0338\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1438.3302 - mse: 1438.3302\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 998us/step - loss: 870.0711 - mse: 870.0711\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 673.9323 - mse: 673.9323\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 417.9525 - mse: 417.9525\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 476.6215 - mse: 476.6215\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 344.5898 - mse: 344.5898\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 301.2835 - mse: 301.2835\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 339.1860 - mse: 339.1860\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 315.2970 - mse: 315.2970\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 287.0774 - mse: 287.0774\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 282.0797 - mse: 282.0797\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 258.0594 - mse: 258.0594\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 257.0604 - mse: 257.0604\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 322.8039 - mse: 322.8039\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 262.4719 - mse: 262.4719\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 265.3137 - mse: 265.3137\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 294.5268 - mse: 294.5268\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 232.0319 - mse: 232.0319\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 238.7226 - mse: 238.7226\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 247.1055 - mse: 247.1055\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 231.0612 - mse: 231.0612\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 226.3587 - mse: 226.3587\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 234.5566 - mse: 234.5566\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 230.5611 - mse: 230.5611\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.3236 - mse: 236.3236\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 223.3246 - mse: 223.3246\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 220.2233 - mse: 220.2233\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 219.2212 - mse: 219.2212\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 215.8393 - mse: 215.8393\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 233.3062 - mse: 233.3062\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 221.4832 - mse: 221.4832\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 257.1453 - mse: 257.1453\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 996us/step - loss: 222.5336 - mse: 222.5336\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.6439 - mse: 236.6439\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 217.8157 - mse: 217.8157\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 225.2977 - mse: 225.2977\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 217.4597 - mse: 217.4597\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 220.6247 - mse: 220.6247\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 226.9212 - mse: 226.9212\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 997us/step - loss: 255.6980 - mse: 255.6980\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 217.2862 - mse: 217.2862\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 244.0547 - mse: 244.0547\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 217.1655 - mse: 217.1655\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 275.5969 - mse: 275.5969\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 259.5637 - mse: 259.5637\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 253.7247 - mse: 253.7247\n",
      "WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7E5128940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 290.6280 - mse: 290.6280\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 15657.4441 - mse: 15657.4441\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6475.7825 - mse: 6475.7825\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7257.2285 - mse: 7257.2285\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6079.9967 - mse: 6079.9966\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4969.5497 - mse: 4969.5497\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3276.3900 - mse: 3276.3900\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1865.4192 - mse: 1865.4192\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1195.0189 - mse: 1195.0189\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 579.7239 - mse: 579.7239\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 459.3346 - mse: 459.3346\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 588.9281 - mse: 588.9281\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 476.2371 - mse: 476.2371\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 308.4091 - mse: 308.4091\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 291.0577 - mse: 291.0577\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 307.1745 - mse: 307.1745\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 272.2783 - mse: 272.2783\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 237.1977 - mse: 237.1977\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 240.1520 - mse: 240.1520\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 247.2184 - mse: 247.2184\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 240.2931 - mse: 240.2931\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 226.8193 - mse: 226.8193\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 221.1549 - mse: 221.1549\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 219.1835 - mse: 219.1835\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 217.5555 - mse: 217.5555\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 215.8485 - mse: 215.8485\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 215.7088 - mse: 215.7088\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 213.4556 - mse: 213.4556\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.5097 - mse: 211.5097\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 212.1526 - mse: 212.1526\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.6465 - mse: 210.6465\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 211.0729 - mse: 211.0729\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.0743 - mse: 211.0743\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 212.1238 - mse: 212.1238\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.3851 - mse: 210.3851\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.6557 - mse: 211.6557\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.8352 - mse: 210.8352\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 209.5821 - mse: 209.5821\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 208.9506 - mse: 208.9506\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.5855 - mse: 210.5855\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 209.7673 - mse: 209.7673\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 208.3872 - mse: 208.3872\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 209.6242 - mse: 209.6242\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 209.1960 - mse: 209.1960\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 209.3593 - mse: 209.3593\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 209.8854 - mse: 209.8854\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.3784 - mse: 210.3784\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 208.3046 - mse: 208.3046\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 209.1610 - mse: 209.1610\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 208.0397 - mse: 208.0397\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 207.9176 - mse: 207.9176\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EE047B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 223.9431 - mse: 223.9431\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 15751.5884 - mse: 15751.5884\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4870.3281 - mse: 4870.3281\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3706.0435 - mse: 3706.0435\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1199.9957 - mse: 1199.9957\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2219.9414 - mse: 2219.9414\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1074.1069 - mse: 1074.1069\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 560.1315 - mse: 560.1315\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 653.6457 - mse: 653.6457\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 329.5397 - mse: 329.5397\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 483.4488 - mse: 483.4488\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 327.5395 - mse: 327.5395\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 283.3722 - mse: 283.3722\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 293.2275 - mse: 293.2275\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 233.6383 - mse: 233.6383\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 258.1251 - mse: 258.1251\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 223.6674 - mse: 223.6674\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 231.2732 - mse: 231.2732\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 225.6429 - mse: 225.6429\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 221.6455 - mse: 221.6455\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 224.9945 - mse: 224.9945\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 216.7440 - mse: 216.7440\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 221.8243 - mse: 221.8243\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 216.6739 - mse: 216.6739\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 216.3875 - mse: 216.3875\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 214.2274 - mse: 214.2274\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 215.8749 - mse: 215.8749\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 214.7961 - mse: 214.7961\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 216.3165 - mse: 216.3165\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 215.0827 - mse: 215.0827\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 214.4932 - mse: 214.4932\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 214.8912 - mse: 214.8912\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 213.0254 - mse: 213.0254\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 213.4750 - mse: 213.4750\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 213.3399 - mse: 213.3399\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 212.9912 - mse: 212.9912\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 213.1714 - mse: 213.1714\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 214.4499 - mse: 214.4499\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 212.9495 - mse: 212.9495\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 211.3396 - mse: 211.3396\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 212.6117 - mse: 212.6117\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 213.1645 - mse: 213.1645\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 211.7831 - mse: 211.7831\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.9168 - mse: 210.9168\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 212.2374 - mse: 212.2374\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 211.1087 - mse: 211.1087\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 211.1273 - mse: 211.1273\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.2061 - mse: 210.2061\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.9997 - mse: 210.9997\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 208.7613 - mse: 208.7613\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 997us/step - loss: 209.5296 - mse: 209.5296\n",
      "WARNING:tensorflow:11 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EB527430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 232.2053 - mse: 232.2053\n",
      "Epoch 1/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 15895.7891 - mse: 15895.7891\n",
      "Epoch 2/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 41316.8447 - mse: 41316.8418\n",
      "Epoch 3/60\n",
      "3/3 [==============================] - 0s 997us/step - loss: 13447.6084 - mse: 13447.6084\n",
      "Epoch 4/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16663.7197 - mse: 16663.7222\n",
      "Epoch 5/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 16860.0947 - mse: 16860.0947\n",
      "Epoch 6/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16765.7324 - mse: 16765.7324\n",
      "Epoch 7/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16468.9023 - mse: 16468.9038\n",
      "Epoch 8/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16097.0771 - mse: 16097.0771\n",
      "Epoch 9/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 15511.6060 - mse: 15511.6060\n",
      "Epoch 10/60\n",
      "3/3 [==============================] - 0s 996us/step - loss: 14836.6113 - mse: 14836.6113\n",
      "Epoch 11/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 14005.4404 - mse: 14005.4404\n",
      "Epoch 12/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 12891.6770 - mse: 12891.6770\n",
      "Epoch 13/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 11484.7861 - mse: 11484.7861\n",
      "Epoch 14/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9631.4434 - mse: 9631.4434\n",
      "Epoch 15/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7378.5796 - mse: 7378.5796\n",
      "Epoch 16/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4793.6265 - mse: 4793.6265\n",
      "Epoch 17/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2306.6401 - mse: 2306.6401\n",
      "Epoch 18/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 587.0616 - mse: 587.0616\n",
      "Epoch 19/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 572.9431 - mse: 572.9431\n",
      "Epoch 20/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1228.8847 - mse: 1228.8847\n",
      "Epoch 21/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 865.9889 - mse: 865.9889\n",
      "Epoch 22/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 435.9229 - mse: 435.9229\n",
      "Epoch 23/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 268.4090 - mse: 268.4090\n",
      "Epoch 24/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 228.6488 - mse: 228.6488\n",
      "Epoch 25/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 247.3087 - mse: 247.3087\n",
      "Epoch 26/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 267.7232 - mse: 267.7232\n",
      "Epoch 27/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 271.8147 - mse: 271.8147\n",
      "Epoch 28/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 254.9418 - mse: 254.9418\n",
      "Epoch 29/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.6409 - mse: 236.6409\n",
      "Epoch 30/60\n",
      "3/3 [==============================] - 0s 998us/step - loss: 229.2440 - mse: 229.2440\n",
      "Epoch 31/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 231.6634 - mse: 231.6634\n",
      "Epoch 32/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 234.9762 - mse: 234.9762\n",
      "Epoch 33/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 234.6965 - mse: 234.6965\n",
      "Epoch 34/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 233.4637 - mse: 233.4637\n",
      "Epoch 35/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 229.6907 - mse: 229.6907\n",
      "Epoch 36/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 231.5508 - mse: 231.5508\n",
      "Epoch 37/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 228.5983 - mse: 228.5983\n",
      "Epoch 38/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 229.9013 - mse: 229.9013\n",
      "Epoch 39/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 228.4058 - mse: 228.4058\n",
      "Epoch 40/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 228.8715 - mse: 228.8715\n",
      "Epoch 41/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 229.4653 - mse: 229.4653\n",
      "Epoch 42/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 228.5560 - mse: 228.5560\n",
      "Epoch 43/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 228.8040 - mse: 228.8040\n",
      "Epoch 44/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 230.4330 - mse: 230.4330\n",
      "Epoch 45/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 229.7058 - mse: 229.7058\n",
      "Epoch 46/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 230.7350 - mse: 230.7350\n",
      "Epoch 47/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 227.5121 - mse: 227.5121\n",
      "Epoch 48/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 229.8021 - mse: 229.8021\n",
      "Epoch 49/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 229.0721 - mse: 229.0721\n",
      "Epoch 50/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 229.5128 - mse: 229.5128\n",
      "Epoch 51/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 228.7509 - mse: 228.7509\n",
      "Epoch 52/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 228.3483 - mse: 228.3483\n",
      "Epoch 53/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 229.1633 - mse: 229.1633\n",
      "Epoch 54/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 226.5792 - mse: 226.5792\n",
      "Epoch 55/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 228.5778 - mse: 228.5778\n",
      "Epoch 56/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 227.9939 - mse: 227.9939\n",
      "Epoch 57/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 228.5523 - mse: 228.5523\n",
      "Epoch 58/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 228.2047 - mse: 228.2047\n",
      "Epoch 59/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 227.8885 - mse: 227.8885\n",
      "Epoch 60/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 230.1585 - mse: 230.1585\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7ECB471F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 338.9380 - mse: 338.9380\n",
      "Epoch 1/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 15638.6294 - mse: 15638.6294\n",
      "Epoch 2/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7148.3198 - mse: 7148.3198\n",
      "Epoch 3/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 14492.3428 - mse: 14492.3428\n",
      "Epoch 4/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 12033.9006 - mse: 12033.9006\n",
      "Epoch 5/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7288.2394 - mse: 7288.2394\n",
      "Epoch 6/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4366.9562 - mse: 4366.9562\n",
      "Epoch 7/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2054.6666 - mse: 2054.6664\n",
      "Epoch 8/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1802.4325 - mse: 1802.4325\n",
      "Epoch 9/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 863.0001 - mse: 863.0001\n",
      "Epoch 10/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1103.7868 - mse: 1103.7869\n",
      "Epoch 11/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 640.9414 - mse: 640.9414\n",
      "Epoch 12/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 499.1385 - mse: 499.1385\n",
      "Epoch 13/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 595.5038 - mse: 595.5038\n",
      "Epoch 14/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 341.3732 - mse: 341.3732\n",
      "Epoch 15/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 359.7547 - mse: 359.7547\n",
      "Epoch 16/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 398.1194 - mse: 398.1194\n",
      "Epoch 17/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 281.0684 - mse: 281.0684\n",
      "Epoch 18/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 288.0537 - mse: 288.0537\n",
      "Epoch 19/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 306.9728 - mse: 306.9728\n",
      "Epoch 20/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 268.7279 - mse: 268.7279\n",
      "Epoch 21/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 257.0419 - mse: 257.0419\n",
      "Epoch 22/60\n",
      "3/3 [==============================] - 0s 996us/step - loss: 267.9636 - mse: 267.9636\n",
      "Epoch 23/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 254.4232 - mse: 254.4232\n",
      "Epoch 24/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 248.5974 - mse: 248.5974\n",
      "Epoch 25/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 252.4415 - mse: 252.4415\n",
      "Epoch 26/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 249.6350 - mse: 249.6350\n",
      "Epoch 27/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 246.3768 - mse: 246.3768\n",
      "Epoch 28/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 244.5859 - mse: 244.5859\n",
      "Epoch 29/60\n",
      "3/3 [==============================] - 0s 996us/step - loss: 247.1181 - mse: 247.1181\n",
      "Epoch 30/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 247.0219 - mse: 247.0219\n",
      "Epoch 31/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 245.9378 - mse: 245.9378\n",
      "Epoch 32/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 247.4737 - mse: 247.4737\n",
      "Epoch 33/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 245.4296 - mse: 245.4296\n",
      "Epoch 34/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 245.0998 - mse: 245.0998\n",
      "Epoch 35/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 243.8040 - mse: 243.8040\n",
      "Epoch 36/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 242.7310 - mse: 242.7310\n",
      "Epoch 37/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 243.2261 - mse: 243.2261\n",
      "Epoch 38/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 245.3122 - mse: 245.3122\n",
      "Epoch 39/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 244.8621 - mse: 244.8621\n",
      "Epoch 40/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 245.0109 - mse: 245.0109\n",
      "Epoch 41/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 245.3869 - mse: 245.3869\n",
      "Epoch 42/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 243.6851 - mse: 243.6851\n",
      "Epoch 43/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 243.6590 - mse: 243.6590\n",
      "Epoch 44/60\n",
      "3/3 [==============================] - 0s 997us/step - loss: 243.2637 - mse: 243.2637\n",
      "Epoch 45/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 243.6334 - mse: 243.6334\n",
      "Epoch 46/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 244.2071 - mse: 244.2071\n",
      "Epoch 47/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 242.5296 - mse: 242.5296\n",
      "Epoch 48/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 242.2652 - mse: 242.2652\n",
      "Epoch 49/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 240.5845 - mse: 240.5845\n",
      "Epoch 50/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 241.2575 - mse: 241.2575\n",
      "Epoch 51/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 242.4615 - mse: 242.4615\n",
      "Epoch 52/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 241.6566 - mse: 241.6566\n",
      "Epoch 53/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 242.7023 - mse: 242.7023\n",
      "Epoch 54/60\n",
      "3/3 [==============================] - 0s 997us/step - loss: 242.1341 - mse: 242.1341\n",
      "Epoch 55/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 244.3476 - mse: 244.3476\n",
      "Epoch 56/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 241.6978 - mse: 241.6978\n",
      "Epoch 57/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 241.0315 - mse: 241.0315\n",
      "Epoch 58/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 241.3630 - mse: 241.3630\n",
      "Epoch 59/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 240.7569 - mse: 240.7569\n",
      "Epoch 60/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 243.2479 - mse: 243.2479\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EE42D550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 103.5726 - mse: 103.5726\n",
      "Epoch 1/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 28790.2483 - mse: 28790.2483\n",
      "Epoch 2/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6234.9327 - mse: 6234.9327\n",
      "Epoch 3/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 17687.8862 - mse: 17687.8862\n",
      "Epoch 4/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 17449.3008 - mse: 17449.3008\n",
      "Epoch 5/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16378.8625 - mse: 16378.8625\n",
      "Epoch 6/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 14235.2158 - mse: 14235.2158\n",
      "Epoch 7/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 11061.7002 - mse: 11061.7000\n",
      "Epoch 8/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7210.3796 - mse: 7210.3796\n",
      "Epoch 9/60\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3398.5198 - mse: 3398.5198\n",
      "Epoch 10/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 797.1664 - mse: 797.1664\n",
      "Epoch 11/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 422.7584 - mse: 422.7584\n",
      "Epoch 12/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1526.9740 - mse: 1526.9740\n",
      "Epoch 13/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1790.0082 - mse: 1790.0082\n",
      "Epoch 14/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1003.5208 - mse: 1003.5208\n",
      "Epoch 15/60\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 347.3552 - mse: 347.3552\n",
      "Epoch 16/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 277.2493 - mse: 277.2493\n",
      "Epoch 17/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 467.1326 - mse: 467.1326\n",
      "Epoch 18/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 559.0059 - mse: 559.0059\n",
      "Epoch 19/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 462.0668 - mse: 462.0668\n",
      "Epoch 20/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 312.9416 - mse: 312.9416\n",
      "Epoch 21/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 239.6355 - mse: 239.6355\n",
      "Epoch 22/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 265.1898 - mse: 265.1898\n",
      "Epoch 23/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 301.2777 - mse: 301.2777\n",
      "Epoch 24/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 288.0077 - mse: 288.0077\n",
      "Epoch 25/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 249.9089 - mse: 249.9089\n",
      "Epoch 26/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.7640 - mse: 236.7640\n",
      "Epoch 27/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 244.5043 - mse: 244.5043\n",
      "Epoch 28/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 251.1324 - mse: 251.1324\n",
      "Epoch 29/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 247.0758 - mse: 247.0758\n",
      "Epoch 30/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 236.3609 - mse: 236.3609\n",
      "Epoch 31/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.7745 - mse: 235.7745\n",
      "Epoch 32/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 238.2144 - mse: 238.2144\n",
      "Epoch 33/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 238.0651 - mse: 238.0651\n",
      "Epoch 34/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 238.2821 - mse: 238.2821\n",
      "Epoch 35/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.7628 - mse: 235.7628\n",
      "Epoch 36/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 237.6566 - mse: 237.6566\n",
      "Epoch 37/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 237.5829 - mse: 237.5829\n",
      "Epoch 38/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 237.1833 - mse: 237.1833\n",
      "Epoch 39/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 237.3061 - mse: 237.3061\n",
      "Epoch 40/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.6742 - mse: 236.6742\n",
      "Epoch 41/60\n",
      "3/3 [==============================] - 0s 997us/step - loss: 234.9892 - mse: 234.9892\n",
      "Epoch 42/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 237.1842 - mse: 237.1842\n",
      "Epoch 43/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.2282 - mse: 236.2282\n",
      "Epoch 44/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.1278 - mse: 236.1278\n",
      "Epoch 45/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 234.2080 - mse: 234.2080\n",
      "Epoch 46/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.1222 - mse: 235.1222\n",
      "Epoch 47/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.4435 - mse: 236.4435\n",
      "Epoch 48/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 237.0491 - mse: 237.0491\n",
      "Epoch 49/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 238.4834 - mse: 238.4834\n",
      "Epoch 50/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.5308 - mse: 236.5308\n",
      "Epoch 51/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.8158 - mse: 235.8158\n",
      "Epoch 52/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.2823 - mse: 236.2823\n",
      "Epoch 53/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.6243 - mse: 236.6243\n",
      "Epoch 54/60\n",
      "3/3 [==============================] - 0s 997us/step - loss: 236.3191 - mse: 236.3191\n",
      "Epoch 55/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 234.7023 - mse: 234.7023\n",
      "Epoch 56/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 236.8355 - mse: 236.8355\n",
      "Epoch 57/60\n",
      "3/3 [==============================] - 0s 998us/step - loss: 236.3628 - mse: 236.3628\n",
      "Epoch 58/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.3277 - mse: 235.3277\n",
      "Epoch 59/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.7841 - mse: 235.7841\n",
      "Epoch 60/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 237.5714 - mse: 237.5714\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7ECA63280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 312.5901 - mse: 312.5901\n",
      "Epoch 1/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16531.3528 - mse: 16531.3528\n",
      "Epoch 2/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 8345.0616 - mse: 8345.0616\n",
      "Epoch 3/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 13726.4214 - mse: 13726.4214\n",
      "Epoch 4/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9586.1311 - mse: 9586.1311\n",
      "Epoch 5/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7631.0588 - mse: 7631.0588\n",
      "Epoch 6/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5481.5530 - mse: 5481.5530\n",
      "Epoch 7/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3514.7863 - mse: 3514.7863\n",
      "Epoch 8/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2032.1076 - mse: 2032.1077\n",
      "Epoch 9/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1725.4338 - mse: 1725.4338\n",
      "Epoch 10/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 798.1507 - mse: 798.1507\n",
      "Epoch 11/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 750.4045 - mse: 750.4045\n",
      "Epoch 12/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 783.9683 - mse: 783.9683\n",
      "Epoch 13/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 456.4100 - mse: 456.4100\n",
      "Epoch 14/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 477.5102 - mse: 477.5102\n",
      "Epoch 15/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 474.5776 - mse: 474.5776\n",
      "Epoch 16/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 391.0269 - mse: 391.0269\n",
      "Epoch 17/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 309.9695 - mse: 309.9696\n",
      "Epoch 18/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 297.9588 - mse: 297.9588\n",
      "Epoch 19/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 259.3923 - mse: 259.3923\n",
      "Epoch 20/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 240.3884 - mse: 240.3884\n",
      "Epoch 21/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 256.5149 - mse: 256.5149\n",
      "Epoch 22/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 254.7541 - mse: 254.7541\n",
      "Epoch 23/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 239.2196 - mse: 239.2196\n",
      "Epoch 24/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 231.7087 - mse: 231.7087\n",
      "Epoch 25/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 232.2183 - mse: 232.2183\n",
      "Epoch 26/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 231.3535 - mse: 231.3535\n",
      "Epoch 27/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 228.2538 - mse: 228.2538\n",
      "Epoch 28/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 225.8951 - mse: 225.8951\n",
      "Epoch 29/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 223.5251 - mse: 223.5251\n",
      "Epoch 30/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 224.0749 - mse: 224.0749\n",
      "Epoch 31/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 223.4367 - mse: 223.4367\n",
      "Epoch 32/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 225.0827 - mse: 225.0827\n",
      "Epoch 33/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 222.3695 - mse: 222.3695\n",
      "Epoch 34/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 223.5533 - mse: 223.5533\n",
      "Epoch 35/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 219.7473 - mse: 219.7473\n",
      "Epoch 36/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 221.7492 - mse: 221.7492\n",
      "Epoch 37/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 222.1562 - mse: 222.1562\n",
      "Epoch 38/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 221.6067 - mse: 221.6067\n",
      "Epoch 39/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 225.6302 - mse: 225.6302\n",
      "Epoch 40/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 219.6191 - mse: 219.6191\n",
      "Epoch 41/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 220.0952 - mse: 220.0952\n",
      "Epoch 42/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 222.5657 - mse: 222.5657\n",
      "Epoch 43/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 219.1179 - mse: 219.1179\n",
      "Epoch 44/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 220.0043 - mse: 220.0043\n",
      "Epoch 45/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 221.3276 - mse: 221.3276\n",
      "Epoch 46/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 221.0701 - mse: 221.0701\n",
      "Epoch 47/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 222.9662 - mse: 222.9662\n",
      "Epoch 48/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 220.5823 - mse: 220.5823\n",
      "Epoch 49/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 217.5443 - mse: 217.5443\n",
      "Epoch 50/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 220.5581 - mse: 220.5581\n",
      "Epoch 51/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 219.5661 - mse: 219.5661\n",
      "Epoch 52/60\n",
      "3/3 [==============================] - 0s 997us/step - loss: 220.4837 - mse: 220.4837\n",
      "Epoch 53/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 218.6172 - mse: 218.6172\n",
      "Epoch 54/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 217.4827 - mse: 217.4827\n",
      "Epoch 55/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 217.6232 - mse: 217.6232\n",
      "Epoch 56/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 218.3922 - mse: 218.3922\n",
      "Epoch 57/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 220.1673 - mse: 220.1673\n",
      "Epoch 58/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 217.7978 - mse: 217.7978\n",
      "Epoch 59/60\n",
      "3/3 [==============================] - 0s 997us/step - loss: 217.8487 - mse: 217.8487\n",
      "Epoch 60/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 218.9418 - mse: 218.9418\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7ECB47040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 224.5806 - mse: 224.5806\n",
      "Epoch 1/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 35199.3936 - mse: 35199.3936\n",
      "Epoch 2/60\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6255.6107 - mse: 6255.6107\n",
      "Epoch 3/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 18254.7432 - mse: 18254.7432\n",
      "Epoch 4/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 18268.5474 - mse: 18268.5474\n",
      "Epoch 5/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 18094.7251 - mse: 18094.7251\n",
      "Epoch 6/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 17854.7202 - mse: 17854.7202\n",
      "Epoch 7/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 17622.2065 - mse: 17622.2065\n",
      "Epoch 8/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 17337.4604 - mse: 17337.4600\n",
      "Epoch 9/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 17051.8857 - mse: 17051.8857\n",
      "Epoch 10/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16745.3428 - mse: 16745.3428\n",
      "Epoch 11/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16413.0415 - mse: 16413.0415\n",
      "Epoch 12/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16150.4692 - mse: 16150.4692\n",
      "Epoch 13/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 15797.9666 - mse: 15797.9666\n",
      "Epoch 14/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 15513.5420 - mse: 15513.5420\n",
      "Epoch 15/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 15186.9360 - mse: 15186.9360\n",
      "Epoch 16/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 14869.7102 - mse: 14869.7102\n",
      "Epoch 17/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 14574.1411 - mse: 14574.1411\n",
      "Epoch 18/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 14252.6997 - mse: 14252.6997\n",
      "Epoch 19/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 13950.0129 - mse: 13950.0129\n",
      "Epoch 20/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 13665.1128 - mse: 13665.1128\n",
      "Epoch 21/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 13359.2019 - mse: 13359.2019\n",
      "Epoch 22/60\n",
      "3/3 [==============================] - 0s 998us/step - loss: 13089.3086 - mse: 13089.3086\n",
      "Epoch 23/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 12789.5508 - mse: 12789.5510\n",
      "Epoch 24/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 12526.2673 - mse: 12526.2673\n",
      "Epoch 25/60\n",
      "3/3 [==============================] - 0s 997us/step - loss: 12258.0146 - mse: 12258.0146\n",
      "Epoch 26/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 11977.7690 - mse: 11977.7678\n",
      "Epoch 27/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 11695.9287 - mse: 11695.9287\n",
      "Epoch 28/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 11420.8691 - mse: 11420.8691\n",
      "Epoch 29/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 11165.1675 - mse: 11165.1675\n",
      "Epoch 30/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 10913.5095 - mse: 10913.5095\n",
      "Epoch 31/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 10672.0674 - mse: 10672.0674\n",
      "Epoch 32/60\n",
      "3/3 [==============================] - 0s 997us/step - loss: 10410.3499 - mse: 10410.3499\n",
      "Epoch 33/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 10152.7751 - mse: 10152.7751\n",
      "Epoch 34/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9912.3057 - mse: 9912.3057\n",
      "Epoch 35/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9681.3408 - mse: 9681.3408\n",
      "Epoch 36/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9459.9153 - mse: 9459.9153\n",
      "Epoch 37/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9213.2720 - mse: 9213.2720\n",
      "Epoch 38/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9002.0623 - mse: 9002.0623\n",
      "Epoch 39/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8793.7588 - mse: 8793.7588\n",
      "Epoch 40/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 8573.2883 - mse: 8573.2883\n",
      "Epoch 41/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8372.4136 - mse: 8372.4136\n",
      "Epoch 42/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8147.9985 - mse: 8147.9985\n",
      "Epoch 43/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7946.3820 - mse: 7946.3820\n",
      "Epoch 44/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7740.3363 - mse: 7740.3363\n",
      "Epoch 45/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7553.0406 - mse: 7553.0406\n",
      "Epoch 46/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7370.8140 - mse: 7370.8140\n",
      "Epoch 47/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7182.9597 - mse: 7182.9597\n",
      "Epoch 48/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6990.9137 - mse: 6990.9137\n",
      "Epoch 49/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6822.6050 - mse: 6822.6050\n",
      "Epoch 50/60\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6644.4716 - mse: 6644.4716\n",
      "Epoch 51/60\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6473.5686 - mse: 6473.5686\n",
      "Epoch 52/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6299.6272 - mse: 6299.6272\n",
      "Epoch 53/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6119.1622 - mse: 6119.1620\n",
      "Epoch 54/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5975.4528 - mse: 5975.4528\n",
      "Epoch 55/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5820.8767 - mse: 5820.8767\n",
      "Epoch 56/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5664.7684 - mse: 5664.7684\n",
      "Epoch 57/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5507.7393 - mse: 5507.7393\n",
      "Epoch 58/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5383.5208 - mse: 5383.5208\n",
      "Epoch 59/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5227.5414 - mse: 5227.5414\n",
      "Epoch 60/60\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5078.0161 - mse: 5078.0162\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EB5274C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 4505.9951 - mse: 4505.9951\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 15113.8618 - mse: 15113.8606\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6967.3406 - mse: 6967.3406\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 11424.0242 - mse: 11424.0242\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3959.8672 - mse: 3959.8672\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3402.3027 - mse: 3402.3027\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3380.7106 - mse: 3380.7106\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1734.2510 - mse: 1734.2510\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1453.4669 - mse: 1453.4669\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1309.7881 - mse: 1309.7881\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 997us/step - loss: 695.7372 - mse: 695.7371\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 663.2020 - mse: 663.2020\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 678.6511 - mse: 678.6511\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 347.4164 - mse: 347.4164\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 318.7671 - mse: 318.7671\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 395.9039 - mse: 395.9039\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 304.9584 - mse: 304.9584\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 248.4592 - mse: 248.4592\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 254.0228 - mse: 254.0228\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 234.7508 - mse: 234.7508\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.2736 - mse: 236.2736\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 221.9414 - mse: 221.9414\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.1459 - mse: 210.1459\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 212.0831 - mse: 212.0831\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 207.3845 - mse: 207.3845\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 209.2182 - mse: 209.2182\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 206.3530 - mse: 206.3530\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 202.1731 - mse: 202.1731\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 204.3567 - mse: 204.3568\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 200.7859 - mse: 200.7859\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 201.2924 - mse: 201.2924\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 200.1511 - mse: 200.1511\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 200.3826 - mse: 200.3826\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 201.4138 - mse: 201.4138\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 200.1723 - mse: 200.1723\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 199.8061 - mse: 199.8061\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 199.3441 - mse: 199.3441\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 199.3898 - mse: 199.3898\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 198.6634 - mse: 198.6634\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 198.9681 - mse: 198.9681\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 198.5888 - mse: 198.5888\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 197.1185 - mse: 197.1185\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 197.9495 - mse: 197.9495\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 197.6849 - mse: 197.6849\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 198.7957 - mse: 198.7957\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 196.4109 - mse: 196.4109\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 196.5714 - mse: 196.5714\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 195.3702 - mse: 195.3702\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 197.9994 - mse: 197.9994\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 197.3592 - mse: 197.3592\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 197.5540 - mse: 197.5540\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 196.2793 - mse: 196.2793\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 196.1012 - mse: 196.1012\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 195.6089 - mse: 195.6089\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 196.3084 - mse: 196.3084\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 196.2494 - mse: 196.2494\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 194.9708 - mse: 194.9708\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 195.8885 - mse: 195.8885\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 196.0823 - mse: 196.0823\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 196.1483 - mse: 196.1483\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 194.9554 - mse: 194.9554\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 194.2733 - mse: 194.2733\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 194.9052 - mse: 194.9052\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 997us/step - loss: 194.9036 - mse: 194.9036\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 193.9295 - mse: 193.9295\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 194.2480 - mse: 194.2480\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 193.7707 - mse: 193.7707\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 194.0302 - mse: 194.0302\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 193.7417 - mse: 193.7417\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 192.3392 - mse: 192.3392\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 192.1786 - mse: 192.1786\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 193.5603 - mse: 193.5603\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 192.3963 - mse: 192.3963\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 194.0748 - mse: 194.0748\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 192.1721 - mse: 192.1721\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 191.8813 - mse: 191.8813\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 191.8306 - mse: 191.8305\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 193.2906 - mse: 193.2906\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 191.8214 - mse: 191.8214\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 191.7753 - mse: 191.7753\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 191.6424 - mse: 191.6424\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 192.1006 - mse: 192.1006\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 191.5453 - mse: 191.5453\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 191.8948 - mse: 191.8948\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 192.3821 - mse: 192.3821\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 190.7923 - mse: 190.7923\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 190.3168 - mse: 190.3168\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 191.2903 - mse: 191.2903\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 189.7945 - mse: 189.7945\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 190.6445 - mse: 190.6445\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 191.5427 - mse: 191.5427\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 189.9972 - mse: 189.9972\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 189.5947 - mse: 189.5947\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 190.2844 - mse: 190.2844\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 188.3418 - mse: 188.3418\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 190.1028 - mse: 190.1028\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 190.7497 - mse: 190.7497\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 189.2050 - mse: 189.2050\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 188.3927 - mse: 188.3927\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 188.3854 - mse: 188.3854\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 189.4364 - mse: 189.4364\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EE11DB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 295.7191 - mse: 295.7191\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 18952.1306 - mse: 18952.1306\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7789.6364 - mse: 7789.6364\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 17606.2554 - mse: 17606.2554\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 17920.2231 - mse: 17920.2231\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 17884.0107 - mse: 17884.0107\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 17538.1265 - mse: 17538.1265\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 17053.1523 - mse: 17053.1523\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16522.4849 - mse: 16522.4849\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16051.8308 - mse: 16051.8308\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 15473.1392 - mse: 15473.1392\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 14825.1582 - mse: 14825.1582\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 14009.6138 - mse: 14009.6138\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 997us/step - loss: 12933.5615 - mse: 12933.5615\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 11509.7092 - mse: 11509.7092\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 9635.3887 - mse: 9635.3887\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7392.3726 - mse: 7392.3726\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4903.9686 - mse: 4903.9686\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2582.4795 - mse: 2582.4795\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 868.4296 - mse: 868.4296\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 393.5268 - mse: 393.5268\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 775.6255 - mse: 775.6256\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 954.1518 - mse: 954.1518\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 885.2602 - mse: 885.2602\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 628.5809 - mse: 628.5809\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 380.9481 - mse: 380.9481\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 285.7120 - mse: 285.7120\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 307.8920 - mse: 307.8920\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 352.5108 - mse: 352.5108\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 371.7876 - mse: 371.7876\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 345.4605 - mse: 345.4605\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 311.9276 - mse: 311.9276\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 285.4949 - mse: 285.4949\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 283.5582 - mse: 283.5582\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 290.5780 - mse: 290.5780\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 295.1477 - mse: 295.1477\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 290.8178 - mse: 290.8178\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 285.8584 - mse: 285.8584\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 283.3520 - mse: 283.3520\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 281.8643 - mse: 281.8643\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 282.1990 - mse: 282.1990\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 285.7174 - mse: 285.7174\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 285.0764 - mse: 285.0764\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 283.9678 - mse: 283.9678\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 283.0348 - mse: 283.0348\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 283.4588 - mse: 283.4588\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 283.5937 - mse: 283.5937\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 284.1141 - mse: 284.1141\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 997us/step - loss: 281.1138 - mse: 281.1138\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 281.1789 - mse: 281.1789\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 283.9373 - mse: 283.9373\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 282.0667 - mse: 282.0667\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 282.4198 - mse: 282.4198\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 283.8100 - mse: 283.8100\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 282.0974 - mse: 282.0974\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 281.3019 - mse: 281.3019\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 283.9052 - mse: 283.9052\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 282.4906 - mse: 282.4906\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 281.2489 - mse: 281.2489\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 282.6710 - mse: 282.6710\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 280.9980 - mse: 280.9980\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 280.5581 - mse: 280.5582\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 282.4339 - mse: 282.4339\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 282.2682 - mse: 282.2682\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 282.6545 - mse: 282.6545\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 282.0832 - mse: 282.0832\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 280.9571 - mse: 280.9571\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 281.7225 - mse: 281.7225\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 282.7957 - mse: 282.7956\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 281.6965 - mse: 281.6965\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 283.4689 - mse: 283.4689\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 284.2813 - mse: 284.2813\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 281.4957 - mse: 281.4957\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 280.8101 - mse: 280.8101\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 281.4339 - mse: 281.4339\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 283.2526 - mse: 283.2526\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 279.6826 - mse: 279.6826\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 997us/step - loss: 281.9176 - mse: 281.9176\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 283.0206 - mse: 283.0206\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 281.2412 - mse: 281.2412\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 283.1407 - mse: 283.1407\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 282.4193 - mse: 282.4193\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 280.8674 - mse: 280.8674\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 997us/step - loss: 281.1314 - mse: 281.1313\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 282.0522 - mse: 282.0522\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 281.5032 - mse: 281.5032\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 282.6962 - mse: 282.6962\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 281.4375 - mse: 281.4375\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 282.2817 - mse: 282.2817\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 283.7334 - mse: 283.7334\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 281.9752 - mse: 281.9752\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 281.8915 - mse: 281.8915\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 284.3114 - mse: 284.3114\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 280.9566 - mse: 280.9566\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 283.5959 - mse: 283.5959\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 282.5679 - mse: 282.5679\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 280.8052 - mse: 280.8052\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 282.6612 - mse: 282.6612\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 281.9003 - mse: 281.9003\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 280.6003 - mse: 280.6003\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 997us/step - loss: 282.0175 - mse: 282.0175\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7E50F71F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 129.3126 - mse: 129.3126\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 28003.3352 - mse: 28003.3352\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6194.0821 - mse: 6194.0821\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 17557.8511 - mse: 17557.8511\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 17423.2231 - mse: 17423.2217\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 16465.9370 - mse: 16465.9370\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 14413.5449 - mse: 14413.5449\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 11285.1184 - mse: 11285.1184\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7390.6993 - mse: 7390.6993\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3568.1024 - mse: 3568.1024\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 871.5868 - mse: 871.5868\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 396.1555 - mse: 396.1555\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1484.7845 - mse: 1484.7846\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1817.7726 - mse: 1817.7726\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1039.4488 - mse: 1039.4488\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 359.4901 - mse: 359.4901\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 269.5260 - mse: 269.5260\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 461.7741 - mse: 461.7741\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 557.2021 - mse: 557.2021\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 472.1668 - mse: 472.1668\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 317.9774 - mse: 317.9774\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 238.5441 - mse: 238.5441\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 263.4623 - mse: 263.4623\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 299.8153 - mse: 299.8153\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 289.6704 - mse: 289.6704\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 251.6293 - mse: 251.6293\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 234.2391 - mse: 234.2391\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 243.7935 - mse: 243.7935\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 251.8746 - mse: 251.8746\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 245.7750 - mse: 245.7750\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 238.0850 - mse: 238.0850\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 234.3687 - mse: 234.3687\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 239.0969 - mse: 239.0969\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 239.2958 - mse: 239.2958\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 238.9328 - mse: 238.9328\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.9786 - mse: 235.9786\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.3617 - mse: 236.3617\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.2536 - mse: 236.2536\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.8157 - mse: 236.8157\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 237.3777 - mse: 237.3777\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 234.9690 - mse: 234.9690\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.7355 - mse: 235.7355\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 237.2655 - mse: 237.2655\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.8589 - mse: 236.8589\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.9660 - mse: 236.9660\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.4930 - mse: 235.4930\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.0250 - mse: 236.0250\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.5008 - mse: 236.5008\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 234.1028 - mse: 234.1028\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.9567 - mse: 235.9567\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.6003 - mse: 235.6003\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.1403 - mse: 236.1403\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.7733 - mse: 235.7733\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.5046 - mse: 235.5046\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.5407 - mse: 235.5407\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.8987 - mse: 235.8987\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 234.9789 - mse: 234.9789\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.5894 - mse: 236.5894\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 234.8113 - mse: 234.8113\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.8417 - mse: 235.8417\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.6897 - mse: 236.6897\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 236.6819 - mse: 236.6819\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.1155 - mse: 235.1155\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.1472 - mse: 235.1472\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 235.2972 - mse: 235.2972\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.3948 - mse: 235.3948\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 237.2094 - mse: 237.2094\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.9418 - mse: 235.9418\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 237.4979 - mse: 237.4979\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.7813 - mse: 235.7813\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.8623 - mse: 235.8623\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 237.5433 - mse: 237.5433\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.1964 - mse: 236.1964\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 237.0006 - mse: 237.0006\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.2999 - mse: 235.2999\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.4248 - mse: 236.4248\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.8634 - mse: 235.8634\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.4656 - mse: 235.4656\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 237.1570 - mse: 237.1570\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 237.5607 - mse: 237.5607\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.2713 - mse: 235.2713\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.9571 - mse: 235.9571\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 997us/step - loss: 234.7896 - mse: 234.7896\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.5275 - mse: 236.5275\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.4893 - mse: 235.4893\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.8163 - mse: 235.8163\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 234.9553 - mse: 234.9553\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.7753 - mse: 235.7753\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 234.5936 - mse: 234.5936\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 237.9533 - mse: 237.9533\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.6840 - mse: 235.6840\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 235.7556 - mse: 235.7556\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.3308 - mse: 236.3308\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.4557 - mse: 236.4557\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 237.3137 - mse: 237.3137\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.1869 - mse: 236.1869\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.0826 - mse: 236.0826\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.3108 - mse: 235.3108\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 236.3541 - mse: 236.3541\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.1095 - mse: 235.1095\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 233.8633 - mse: 233.8633\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EB527700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 314.7491 - mse: 314.7491\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 16194.1538 - mse: 16194.1538\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7515.6110 - mse: 7515.6110\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 14219.0999 - mse: 14219.0999\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 11868.5000 - mse: 11868.5000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 10651.3740 - mse: 10651.3740\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8268.4907 - mse: 8268.4907\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6074.1012 - mse: 6074.1012\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2910.0731 - mse: 2910.0731\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1342.6948 - mse: 1342.6948\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1657.8753 - mse: 1657.8753\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1422.0615 - mse: 1422.0615\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 675.1109 - mse: 675.1109\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 357.7722 - mse: 357.7722\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 331.6628 - mse: 331.6628\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 321.8440 - mse: 321.8440\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 297.4069 - mse: 297.4069\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 277.6443 - mse: 277.6443\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 260.3446 - mse: 260.3446\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 248.0062 - mse: 248.0062\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 232.2172 - mse: 232.2172\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 232.0547 - mse: 232.0547\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 224.8209 - mse: 224.8209\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 222.9594 - mse: 222.9594\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 220.7950 - mse: 220.7950\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 224.6986 - mse: 224.6986\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 226.6900 - mse: 226.6900\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 225.1387 - mse: 225.1387\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 997us/step - loss: 235.0044 - mse: 235.0044\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 222.7071 - mse: 222.7071\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 229.6203 - mse: 229.6203\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 217.5432 - mse: 217.5432\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 218.4490 - mse: 218.4490\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 218.2023 - mse: 218.2023\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 215.7042 - mse: 215.7042\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 217.5070 - mse: 217.5070\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 215.7517 - mse: 215.7517\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 221.3576 - mse: 221.3576\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 217.2561 - mse: 217.2561\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 230.0121 - mse: 230.0121\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 239.0322 - mse: 239.0322\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 221.1691 - mse: 221.1691\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 235.8207 - mse: 235.8207\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 238.6938 - mse: 238.6938\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 215.8349 - mse: 215.8349\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 998us/step - loss: 214.8768 - mse: 214.8768\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 216.2556 - mse: 216.2556\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 214.0149 - mse: 214.0149\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 217.0770 - mse: 217.0770\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 215.4579 - mse: 215.4579\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 997us/step - loss: 215.0428 - mse: 215.0428\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 212.3903 - mse: 212.3903\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 214.5129 - mse: 214.5129\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 213.7303 - mse: 213.7303\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 213.5294 - mse: 213.5294\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 217.0531 - mse: 217.0531\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 216.4760 - mse: 216.4760\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 214.9440 - mse: 214.9440\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 212.8547 - mse: 212.8547\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 214.1001 - mse: 214.1001\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 221.8070 - mse: 221.8070\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 227.0557 - mse: 227.0557\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 237.8494 - mse: 237.8494\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 228.2250 - mse: 228.2250\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 230.4757 - mse: 230.4757\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 220.3773 - mse: 220.3773\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 224.4190 - mse: 224.4190\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 233.9007 - mse: 233.9007\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 232.1003 - mse: 232.1003\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 226.9069 - mse: 226.9069\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 224.1317 - mse: 224.1317\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 231.7013 - mse: 231.7013\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 226.4612 - mse: 226.4612\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 221.8391 - mse: 221.8391\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 222.8968 - mse: 222.8968\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 225.9225 - mse: 225.9225\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 217.8695 - mse: 217.8695\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 214.1704 - mse: 214.1704\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.5147 - mse: 211.5147\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 213.5607 - mse: 213.5607\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 212.2911 - mse: 212.2911\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 997us/step - loss: 214.3880 - mse: 214.3880\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 215.2640 - mse: 215.2640\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 212.0235 - mse: 212.0235\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 212.1080 - mse: 212.1080\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 212.4665 - mse: 212.4665\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.7376 - mse: 211.7376\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 209.9305 - mse: 209.9305\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.8768 - mse: 210.8768\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 212.2893 - mse: 212.2893\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 211.0720 - mse: 211.0720\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.8839 - mse: 211.8839\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.8231 - mse: 210.8231\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.1746 - mse: 211.1746\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 210.2815 - mse: 210.2815\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 998us/step - loss: 214.1850 - mse: 214.1850\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 217.3165 - mse: 217.3165\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 212.2507 - mse: 212.2507\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 211.7062 - mse: 211.7062\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.5007 - mse: 211.5007\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 997us/step - loss: 213.6139 - mse: 213.6139\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EE3CBEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 221.5453 - mse: 221.5453\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 16003.3088 - mse: 16003.3088\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8658.7847 - mse: 8658.7847\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 13379.3928 - mse: 13379.3928\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7155.3739 - mse: 7155.3739\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6018.9561 - mse: 6018.9561\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2758.0509 - mse: 2758.0509\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1891.3108 - mse: 1891.3108\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1511.8804 - mse: 1511.8804\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1361.8437 - mse: 1361.8437\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 811.8595 - mse: 811.8595\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 415.8505 - mse: 415.8505\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 749.5853 - mse: 749.5853\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 443.6188 - mse: 443.6188\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 285.8325 - mse: 285.8325\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 352.0327 - mse: 352.0327\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 318.6420 - mse: 318.6420\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 272.8912 - mse: 272.8912\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 256.6898 - mse: 256.6898\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 234.3685 - mse: 234.3685\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 234.3556 - mse: 234.3556\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 239.9815 - mse: 239.9815\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 224.0518 - mse: 224.0518\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 221.2221 - mse: 221.2221\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 224.1068 - mse: 224.1068\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 221.4858 - mse: 221.4858\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 220.4061 - mse: 220.4061\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 220.5397 - mse: 220.5397\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 219.3841 - mse: 219.3841\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 217.2838 - mse: 217.2838\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 218.2617 - mse: 218.2617\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 218.1662 - mse: 218.1662\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 217.1763 - mse: 217.1763\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 216.1881 - mse: 216.1881\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 218.2601 - mse: 218.2601\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 218.2229 - mse: 218.2229\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 215.3916 - mse: 215.3916\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 216.3660 - mse: 216.3660\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 217.0446 - mse: 217.0446\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 214.8663 - mse: 214.8663\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 215.8137 - mse: 215.8137\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 214.0977 - mse: 214.0977\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 997us/step - loss: 215.6037 - mse: 215.6037\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 213.6093 - mse: 213.6093\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 213.3440 - mse: 213.3440\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 215.5460 - mse: 215.5460\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 214.5108 - mse: 214.5108\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 214.9051 - mse: 214.9051\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 212.4239 - mse: 212.4239\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 214.2578 - mse: 214.2578\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 212.7481 - mse: 212.7481\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 213.2127 - mse: 213.2127\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 212.7302 - mse: 212.7302\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 215.0173 - mse: 215.0173\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.6643 - mse: 211.6643\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 212.6525 - mse: 212.6525\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 212.9079 - mse: 212.9079\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 212.9980 - mse: 212.9980\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.7795 - mse: 211.7795\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 213.1603 - mse: 213.1603\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 213.0724 - mse: 213.0724\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 213.6591 - mse: 213.6591\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 211.2286 - mse: 211.2286\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.7412 - mse: 211.7412\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 214.2608 - mse: 214.2608\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.1838 - mse: 211.1838\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 213.5186 - mse: 213.5186\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.5100 - mse: 211.5100\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 998us/step - loss: 212.0666 - mse: 212.0666\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 212.7270 - mse: 212.7270\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 212.8755 - mse: 212.8755\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.6361 - mse: 210.6361\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 211.4077 - mse: 211.4077\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.3613 - mse: 211.3613\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.6514 - mse: 210.6514\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 211.3037 - mse: 211.3037\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.8532 - mse: 211.8532\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 998us/step - loss: 211.9382 - mse: 211.9382\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 211.9663 - mse: 211.9663\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.7234 - mse: 210.7234\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.7044 - mse: 210.7044\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.6941 - mse: 210.6941\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.8014 - mse: 210.8014\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.1337 - mse: 210.1337\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 209.9054 - mse: 209.9054\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.7290 - mse: 210.7290\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.9623 - mse: 211.9623\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 208.3076 - mse: 208.3076\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.7461 - mse: 210.7461\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.9331 - mse: 210.9331\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.9345 - mse: 210.9345\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 209.9271 - mse: 209.9271\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 208.9709 - mse: 208.9709\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 209.7372 - mse: 209.7372\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.1959 - mse: 211.1959\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 209.3293 - mse: 209.3293\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.3977 - mse: 210.3977\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.0188 - mse: 211.0188\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 210.5938 - mse: 210.5938\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 208.8439 - mse: 208.8439\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.0716 - mse: 210.0716\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EE11D4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 227.0002 - mse: 227.0002\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 19562.1408 - mse: 19562.1408\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 13808.8916 - mse: 13808.8916\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 17045.4051 - mse: 17045.4051\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 16985.1695 - mse: 16985.1707\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 16371.9744 - mse: 16371.9744\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 15092.8820 - mse: 15092.8820\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 12959.9525 - mse: 12959.9510\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 9450.3402 - mse: 9450.3402\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 3760.9936 - mse: 3760.9936\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2650.7470 - mse: 2650.7470\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 352.5549 - mse: 352.5549\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 321.7191 - mse: 321.7191\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 559.0015 - mse: 559.0015\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 423.8096 - mse: 423.8096\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 261.9821 - mse: 261.9821\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 293.6089 - mse: 293.6089\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 305.7732 - mse: 305.7732\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 266.7115 - mse: 266.7115\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 255.9557 - mse: 255.9557\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 263.9633 - mse: 263.9633\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 256.2459 - mse: 256.2459\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 252.5959 - mse: 252.5959\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 252.1854 - mse: 252.1854\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 250.0258 - mse: 250.0258\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 250.3569 - mse: 250.3569\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 250.1780 - mse: 250.1780\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 249.0790 - mse: 249.0790\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 997us/step - loss: 248.8897 - mse: 248.8897\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 248.0149 - mse: 248.0149\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 248.9299 - mse: 248.9299\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 248.8858 - mse: 248.8858\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 248.0792 - mse: 248.0792\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 248.8654 - mse: 248.8654\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 248.8226 - mse: 248.8226\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 246.5662 - mse: 246.5662\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 245.8063 - mse: 245.8063\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 248.1503 - mse: 248.1503\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 247.0877 - mse: 247.0877\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 245.9785 - mse: 245.9785\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 246.6697 - mse: 246.6697\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 247.1210 - mse: 247.1210\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 246.2139 - mse: 246.2139\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 246.1681 - mse: 246.1681\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 245.7019 - mse: 245.7019\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 245.6353 - mse: 245.6353\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 244.3654 - mse: 244.3654\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 244.1856 - mse: 244.1856\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 245.1852 - mse: 245.1852\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 242.6452 - mse: 242.6452\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 245.1534 - mse: 245.1534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000001B7DD724F40>,\n",
       "             param_grid={'batch_size': [1000, 3000, 5000],\n",
       "                         'epochs': [10, 50, 60, 100]})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6311d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'batch_size': 5000, 'epochs': 50}, -230.8482681274414)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_ , grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9080d7e3",
   "metadata": {},
   "source": [
    "## Grid Search for best learning rate and kernel initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "716ebdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model1(init,learning_rate):    \n",
    "    model1=Sequential()\n",
    "    model1.add(Dense(10,input_dim=3,kernel_initializer=init,activation='relu'))\n",
    "    model1.add(Dense(8,activation='relu'))\n",
    "    model1.add(Dense(12,activation='relu'))\n",
    "    model1.add(Dense(1,activation='linear'))\n",
    "\n",
    "    model1.compile(loss ='mean_squared_error',optimizer=Adam(learning_rate),metrics=['mse'])\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcde282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kr1=KerasRegressor(build_fn=create_model1)\n",
    "grid1=GridSearchCV(estimator=kr1,param_grid={'learning_rate':[0.001,0.5,1],'init':['normal','zero','uniform']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bf5906b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 [==============================] - 0s 412us/step - loss: 16073.7546 - mse: 16073.7546\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001B7EE3CB670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "94/94 [==============================] - 0s 354us/step - loss: 1339.5660 - mse: 1339.5660\n",
      "376/376 [==============================] - 0s 426us/step - loss: 15963.5655 - mse: 15963.5655\n",
      "94/94 [==============================] - 0s 354us/step - loss: 1674.5537 - mse: 1674.5537\n",
      "376/376 [==============================] - 0s 415us/step - loss: 16925.3546 - mse: 16925.3546\n",
      "94/94 [==============================] - 0s 343us/step - loss: 4512.7539 - mse: 4512.7539\n",
      "376/376 [==============================] - 1s 720us/step - loss: 16833.7766 - mse: 16833.7766\n",
      "94/94 [==============================] - 0s 365us/step - loss: 1903.3730 - mse: 1903.3730\n",
      "376/376 [==============================] - 0s 386us/step - loss: 16711.7322 - mse: 16711.7322\n",
      "94/94 [==============================] - 0s 343us/step - loss: 1508.3438 - mse: 1508.3438\n",
      "376/376 [==============================] - 0s 415us/step - loss: 5954.2119 - mse: 5954.2119\n",
      "94/94 [==============================] - 0s 354us/step - loss: 337.2824 - mse: 337.2824\n",
      "376/376 [==============================] - 0s 420us/step - loss: 1529.3461 - mse: 1529.3461\n",
      "94/94 [==============================] - 0s 365us/step - loss: 110.8607 - mse: 110.8607\n",
      "376/376 [==============================] - 0s 415us/step - loss: 1492.3499 - mse: 1492.3499\n",
      "94/94 [==============================] - 0s 354us/step - loss: 239.9136 - mse: 239.9136\n",
      "376/376 [==============================] - 0s 412us/step - loss: 2305.6456 - mse: 2305.6456\n",
      "94/94 [==============================] - 0s 343us/step - loss: 263.1124 - mse: 263.1124\n",
      "376/376 [==============================] - 0s 386us/step - loss: 3796.0277 - mse: 3796.0277\n",
      "94/94 [==============================] - 0s 343us/step - loss: 235.1802 - mse: 235.1802\n",
      "376/376 [==============================] - 0s 407us/step - loss: 10869.6152 - mse: 10869.6152\n",
      "94/94 [==============================] - 0s 344us/step - loss: 343.1160 - mse: 343.1160\n",
      "376/376 [==============================] - 0s 420us/step - loss: 17622.5969 - mse: 17622.5969\n",
      "94/94 [==============================] - 0s 354us/step - loss: 111.6339 - mse: 111.6339\n",
      "376/376 [==============================] - 1s 418us/step - loss: 5038.1564 - mse: 5038.1564\n",
      "94/94 [==============================] - 0s 353us/step - loss: 299.2500 - mse: 299.2500\n",
      "376/376 [==============================] - 0s 420us/step - loss: 1737.6357 - mse: 1737.6357\n",
      "94/94 [==============================] - 0s 354us/step - loss: 272.7336 - mse: 272.7336\n",
      "376/376 [==============================] - 0s 396us/step - loss: 8249.5964 - mse: 8249.5964\n",
      "94/94 [==============================] - 0s 346us/step - loss: 257.9713 - mse: 257.9713\n",
      "376/376 [==============================] - 0s 413us/step - loss: 18088.7614 - mse: 18088.7614\n",
      "94/94 [==============================] - 0s 343us/step - loss: 18702.0098 - mse: 18702.0098\n",
      "376/376 [==============================] - 1s 412us/step - loss: 18579.6027 - mse: 18579.6027\n",
      "94/94 [==============================] - 0s 354us/step - loss: 16877.0957 - mse: 16877.0957\n",
      "376/376 [==============================] - 0s 410us/step - loss: 17891.9491 - mse: 17891.9491\n",
      "94/94 [==============================] - 0s 354us/step - loss: 19365.8828 - mse: 19365.8828\n",
      "376/376 [==============================] - 0s 416us/step - loss: 18202.8971 - mse: 18202.8971\n",
      "94/94 [==============================] - 0s 365us/step - loss: 18407.5039 - mse: 18407.5039\n",
      "376/376 [==============================] - 0s 390us/step - loss: 18402.5747 - mse: 18402.5747\n",
      "94/94 [==============================] - 0s 368us/step - loss: 17429.3594 - mse: 17429.3594\n",
      "376/376 [==============================] - 1s 418us/step - loss: 10002.8991 - mse: 10002.8991\n",
      "94/94 [==============================] - 0s 343us/step - loss: 644.8857 - mse: 644.8857\n",
      "376/376 [==============================] - 0s 404us/step - loss: 10350.2883 - mse: 10350.2883\n",
      "94/94 [==============================] - 0s 354us/step - loss: 218.3778 - mse: 218.3778\n",
      "376/376 [==============================] - 0s 412us/step - loss: 9830.6072 - mse: 9830.6072\n",
      "94/94 [==============================] - 0s 343us/step - loss: 707.6711 - mse: 707.6711\n",
      "376/376 [==============================] - 0s 418us/step - loss: 10114.0248 - mse: 10114.0248\n",
      "94/94 [==============================] - 0s 356us/step - loss: 518.3562 - mse: 518.3562\n",
      "376/376 [==============================] - 1s 386us/step - loss: 10238.9541 - mse: 10238.9541\n",
      "94/94 [==============================] - 0s 364us/step - loss: 405.8291 - mse: 405.8291\n",
      "376/376 [==============================] - 0s 404us/step - loss: 6758.8277 - mse: 6758.8277\n",
      "94/94 [==============================] - 0s 354us/step - loss: 342.3995 - mse: 342.3995\n",
      "376/376 [==============================] - 0s 408us/step - loss: 7019.4331 - mse: 7019.4331\n",
      "94/94 [==============================] - 0s 354us/step - loss: 124.7711 - mse: 124.7711\n",
      "376/376 [==============================] - 0s 410us/step - loss: 6740.7515 - mse: 6740.7515\n",
      "94/94 [==============================] - 0s 354us/step - loss: 317.0116 - mse: 317.0116\n",
      "376/376 [==============================] - 0s 418us/step - loss: 6775.6546 - mse: 6775.6546\n",
      "94/94 [==============================] - 0s 343us/step - loss: 236.5977 - mse: 236.5977\n",
      "376/376 [==============================] - 0s 389us/step - loss: 6910.9798 - mse: 6910.9798\n",
      "94/94 [==============================] - 0s 352us/step - loss: 257.9272 - mse: 257.9272\n",
      "376/376 [==============================] - 0s 420us/step - loss: 16547.1897 - mse: 16547.1897\n",
      "94/94 [==============================] - 0s 353us/step - loss: 4468.1685 - mse: 4468.1685\n",
      "376/376 [==============================] - 0s 412us/step - loss: 17311.8046 - mse: 17311.8046\n",
      "94/94 [==============================] - 0s 354us/step - loss: 2216.2612 - mse: 2216.2612\n",
      "376/376 [==============================] - 0s 415us/step - loss: 17037.6138 - mse: 17037.6138\n",
      "94/94 [==============================] - 0s 349us/step - loss: 8840.4941 - mse: 8840.4941\n",
      "376/376 [==============================] - 0s 418us/step - loss: 16815.4227 - mse: 16815.4227\n",
      "94/94 [==============================] - 0s 354us/step - loss: 2612.0295 - mse: 2612.0295\n",
      "376/376 [==============================] - 0s 384us/step - loss: 18198.1899 - mse: 18198.1899\n",
      "94/94 [==============================] - 0s 365us/step - loss: 10501.9238 - mse: 10501.9238\n",
      "376/376 [==============================] - 0s 410us/step - loss: 1276.1856 - mse: 1276.1856\n",
      "94/94 [==============================] - 0s 354us/step - loss: 322.9363 - mse: 322.9363\n",
      "376/376 [==============================] - 0s 418us/step - loss: 1415.2890 - mse: 1415.2890\n",
      "94/94 [==============================] - 0s 355us/step - loss: 143.9600 - mse: 143.9600\n",
      "376/376 [==============================] - 1s 410us/step - loss: 7126.0679 - mse: 7126.0679\n",
      "94/94 [==============================] - 0s 354us/step - loss: 309.4774 - mse: 309.4774\n",
      "376/376 [==============================] - 0s 410us/step - loss: 1894.6266 - mse: 1894.6266\n",
      "94/94 [==============================] - 0s 386us/step - loss: 259.3996 - mse: 259.3996\n",
      "376/376 [==============================] - 0s 389us/step - loss: 1162.2047 - mse: 1162.2047\n",
      "94/94 [==============================] - 0s 354us/step - loss: 371.8184 - mse: 371.8184\n",
      "376/376 [==============================] - 0s 418us/step - loss: 9316.8408 - mse: 9316.8408\n",
      "94/94 [==============================] - 0s 354us/step - loss: 342.1242 - mse: 342.1242\n",
      "376/376 [==============================] - 1s 412us/step - loss: 9264.4999 - mse: 9264.4999\n",
      "94/94 [==============================] - 0s 343us/step - loss: 128.1756 - mse: 128.1756\n",
      "376/376 [==============================] - 0s 410us/step - loss: 7483.2424 - mse: 7483.2424\n",
      "94/94 [==============================] - 0s 343us/step - loss: 317.0887 - mse: 317.0887\n",
      "376/376 [==============================] - 0s 412us/step - loss: 8917.2644 - mse: 8917.2644\n",
      "94/94 [==============================] - 0s 343us/step - loss: 237.0927 - mse: 237.0927\n",
      "376/376 [==============================] - 0s 391us/step - loss: 2577.6088 - mse: 2577.6088\n",
      "94/94 [==============================] - 0s 354us/step - loss: 272.5609 - mse: 272.5609\n",
      "470/470 [==============================] - 1s 415us/step - loss: 1100.0934 - mse: 1100.0934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000001B7EDFC4520>,\n",
       "             param_grid={'init': ['normal', 'zero', 'uniform'],\n",
       "                         'learning_rate': [0.001, 0.5, 1]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid1.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f83ecd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-237.26986083984374, {'init': 'normal', 'learning_rate': 0.5})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid1.best_score_ , grid1.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0156d1",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec3f5d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model_fin=Sequential()\n",
    "    model_fin.add(Dense(10,input_dim=3,kernel_initializer='uniform',activation='relu'))\n",
    "    model_fin.add(Dense(8,activation='relu'))\n",
    "    model_fin.add(Dense(12,activation='relu'))\n",
    "    model_fin.add(Dense(1,activation='linear'))\n",
    "\n",
    "    model_fin.compile(loss ='mean_squared_error',optimizer=Adam(learning_rate=0.5),metrics=['mse'])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a48b4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 0s 409us/step - loss: 3594.8669 - mse: 3594.8669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b7eb52e250>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fin.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a3ada5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[146.1783 ],\n",
       "       [146.02982],\n",
       "       [145.7893 ],\n",
       "       ...,\n",
       "       [146.33467],\n",
       "       [146.40837],\n",
       "       [146.3767 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model_fin.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dff36aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 0s 327us/step - loss: 293.5590 - mse: 293.5590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[293.5589599609375, 293.5589599609375]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fin.evaluate(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10516ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4559bd7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c1d571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a89c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebd831d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
